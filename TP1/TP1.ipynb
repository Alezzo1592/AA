{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "#Para el ejercicio 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Ejercicio Opcional\n",
    "from arbolDeDecision import MiClasificadorArbol\n",
    "from arbolDeDecision import imprimir_arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego.     \n",
    "X_competencia = pd.read_csv(\"X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "#display(len(X_train))\n",
    "#display(len(X_test))\n",
    "\n",
    "#pd.plotting.scatter_matrix(X, c=y, s=80, figsize=(15, 8), marker='o', alpha=.8);\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. \n",
    "\n",
    "Para poder tomar los datos de desarrollo y evaluación, decidimos utilizar la varianza de los atributos como una primera manera de discriminar los datos. Notamos que la varianza de los datos era muy igual y muy pocos \"minions\" tenían una varianza \"grande\" (mayor a 1.2). Al momento de analizar los datos, descubrimos que si bien estábamos tomando una muestra del 10% de la población, esta muestra de evaluación, no contenía la misma proporción que la población total de datos. De esta manera, decidimos cambiar la forma de separar los datos y decidimos tomar un 10% de los datos positivos y un 10% de los datos negativos. Para poder hacer esto, tomamos la cantidad de datos Positivos y negativos, guardando en 2 listas, los indices de donde se encuentran. Una vez hecho esto, tomamos de forma random\n",
    "los indices correspondientes a los datos positivos y los datos negativos (guardándolos en una lista random_values\n",
    "). Una vez que guardamos los indices en una lista general, se avanza con la toma de los \"minions\" de desarrollo y de evaluación. Si el indice del minion se encuentra en la lista random_values, se toma ese \"minion\" como un \"minion\" de evaluación, de lo contrario, se lo toma como un \"minion\" de desarrollo.\n",
    "\n",
    "### Correcciones para le RTP\n",
    "Cambiamos nuestra implementacion de la separacion de los datos por **train_test_split**. Ademas usamos el parametro **stratify** que se encarga de hacer lo mismo que haciamos antes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#### Data Split ####'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    244\n",
       "1    206\n",
       "Name: output, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    27\n",
       "1    23\n",
       "Name: output, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'#### 0/1 frequency ratio ####'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## dev ##'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.1844660194174756"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'## eval ##'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.173913043478261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_dev, X_eval, y_dev, y_eval = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.10)\n",
    "\n",
    "display(\"#### Data Split ####\")\n",
    "display(y_dev['output'].value_counts())\n",
    "display(y_eval['output'].value_counts())\n",
    "\n",
    "display(\"#### 0/1 frequency ratio ####\")\n",
    "\n",
    "display(\"## dev ##\")\n",
    "display(y_dev['output'].value_counts()[0] / y_dev['output'].value_counts()[1])\n",
    "\n",
    "display(\"## eval ##\")\n",
    "display(y_eval['output'].value_counts()[0] / y_eval['output'].value_counts()[1])\n",
    "\n",
    "#Distribucion de los X de evaluacion\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(X_eval))\n",
    "plt.show()\n",
    "\n",
    "#Distribucion de los X de entrenamiento\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(X_dev))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.**\n",
    "\n",
    "\n",
    "### Correciones para el RTP\n",
    "Ahora usamos predict_proba para calcular el score **AUC_ROC**.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arbol de sklearn ###\n",
    "arbol = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8111</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.7258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.6222</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.7122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.7103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8278</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.7605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8028</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.7195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8111                 0.7000              0.8783   \n",
       "2                         0.8278                 0.6222              0.8741   \n",
       "3                         0.8222                 0.6556              0.8740   \n",
       "4                         0.8278                 0.7222              0.8752   \n",
       "5                         0.8028                 0.6000              0.8571   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.7258  \n",
       "2                          0.7122  \n",
       "3                          0.7103  \n",
       "4                          0.7605  \n",
       "5                          0.7195  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "\n",
    "arbol.fit(X_dev_np, y_dev_np)\n",
    "\n",
    "def get_positive_class_probabilities(arr):\n",
    "    arr_aux = []\n",
    "    for entry in arr:\n",
    "        arr_aux.append(entry[1])\n",
    "    return arr_aux\n",
    "\n",
    "def get_accuracy(y_pred, y_eval_np):\n",
    "    return np.mean(y_pred == y_eval_np)\n",
    "    \n",
    "def show_prediction_accuracy(y_pred, y_eval_np, x_eval_np):\n",
    "    print(\"Predicciones sobre el test set:\\n {}\".format(y_pred))\n",
    "    print(\"Score sobre el test set: {:.2f}\".format(np.mean(y_pred == y_eval_np))) # A mano\n",
    "    print(\"Score sobre el test set: {:.2f}\".format(arbol.score(x_eval_np, y_eval_np))) # Usando el método score.\n",
    "\n",
    "#Generamos los 5 folds\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "accuracy_train      = []\n",
    "accuracy_validation = []\n",
    "roc_train      = []\n",
    "roc_validation = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_dev_np):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    kf_X_train, kf_X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "    kf_y_train, kf_y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "    \n",
    "    # Entrenamos el arbol con el fold actual\n",
    "    arbol.fit(kf_X_train, kf_y_train)\n",
    "    \n",
    "    # Testeamos contra el fold de test para calcular accuracy\n",
    "    kf_y_pred     = arbol.predict(kf_X_test)\n",
    "    kf_y_pred_dev = arbol.predict(kf_X_train)\n",
    "        \n",
    "    # Calculamos accuracy\n",
    "    accuracy_validation.append(get_accuracy(kf_y_pred, kf_y_test) )\n",
    "    accuracy_train.append(get_accuracy(kf_y_pred_dev, kf_y_train) )\n",
    "\n",
    "    # Testeamos contra el fold de test para calcular el score roc\n",
    "    kf_y_pred_proba     = arbol.predict_proba(kf_X_test)\n",
    "    kf_y_pred_dev_proba = arbol.predict_proba(kf_X_train)\n",
    "    \n",
    "    # Calculamos roc score\n",
    "    roc_train.append(sklearn.metrics.roc_auc_score(kf_y_train, get_positive_class_probabilities(kf_y_pred_dev_proba)))\n",
    "    roc_validation.append(sklearn.metrics.roc_auc_score(kf_y_test, get_positive_class_probabilities(kf_y_pred_proba)))\n",
    "    \n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"]   = accuracy_train      # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracy_validation # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"]    = roc_train           # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"]  = roc_validation      # cambiar por aucs_validation\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "# df.plot(kind=\"bar\")\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>0.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>0.7689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8604   \n",
       "1             5                            Gini                       0.9527   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.8388   \n",
       "4             5         Ganancia de Información                       0.9437   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.7303  \n",
       "1                         0.5523  \n",
       "2                         0.6932  \n",
       "3                         0.7287  \n",
       "4                         0.7689  \n",
       "5                         0.6312  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training   = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "np.random.seed(SEED)\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        \n",
    "        arbol = DecisionTreeClassifier(max_depth=altura, criterion=criterio)\n",
    "        arbol.fit(X_dev_np, y_dev_np)\n",
    "        \n",
    "        #Entrenamiento\n",
    "        y_pred = arbol.predict_proba(X_dev_np)\n",
    "        resultados_training.append( sklearn.metrics.roc_auc_score(y_dev_np, get_positive_class_probabilities(y_pred)))\n",
    "        \n",
    "        #Validacion\n",
    "        y_pred = arbol.predict_proba(X_eval_np)\n",
    "        resultados_validation.append( sklearn.metrics.roc_auc_score(y_eval_np, get_positive_class_probabilities(y_pred)))\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"]   = resultados_training# reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio Extra\n",
    "Para esto tomamos como base el arbol del notebook 4 y lo importamos a un archivo .py para usarlo. \n",
    "\n",
    "**Para probarlo, simplemente descomentar la linea del principio de este ejercicio donde se crea el arbol de decision**.\n",
    "\n",
    "Cambios:\n",
    "   - En las preguntas comparar por >= para tomar espacios continuos.\n",
    "   - Agregamos la entropia como calculo de ganancia\n",
    "   - Agregamos los parametros de profundidad maxima y seleccion de criterio para el arbol. \n",
    "\n",
    "### Correcciones para el RTP\n",
    "\n",
    "Agregamos la posibilidad de usar **predict_proba** para calcular el score **AUC_ROC** y arreglamos los problemas de performance. Para esto:\n",
    "\n",
    "   - Calculamos las probabilidades usando las apariciones de elementos que quedaron en las hojas (Para mas info ver la implementacion en arbolDeDecision.py --> get_probas())\n",
    "   - Para acelerar los calculos cambiamos el uso de **DataFrames** por **numpy arrays**, con los cambios necesarios para que corra.\n",
    "\n",
    "Pudimos ver que el score obtenido por nuestro arbol es bastante menor en la mayoria de los casos pero en algunos se acerca bastante al del implementado en sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5194</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.7338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8167</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8139</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.8740</td>\n",
       "      <td>0.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.7441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8028</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.8571</td>\n",
       "      <td>0.7135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.5194                 0.5222              0.8783   \n",
       "2                         0.8167                 0.6667              0.8741   \n",
       "3                         0.8139                 0.6444              0.8740   \n",
       "4                         0.7389                 0.6667              0.8752   \n",
       "5                         0.8028                 0.5889              0.8571   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.7338  \n",
       "2                          0.7041  \n",
       "3                          0.7039  \n",
       "4                          0.7441  \n",
       "5                          0.7135  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arbol = MiClasificadorArbol(max_depth=3)\n",
    "\n",
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "\n",
    "arbol.fit(X_dev_np, y_dev_np)\n",
    "\n",
    "#Generamos los 5 folds\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "accuracy_train      = []\n",
    "accuracy_validation = []\n",
    "roc_train      = []\n",
    "roc_validation = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_dev_np):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    kf_X_train, kf_X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "    kf_y_train, kf_y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "    \n",
    "    # Entrenamos el arbol con el fold actual\n",
    "    arbol.fit(kf_X_train, kf_y_train)\n",
    "    \n",
    "    # Testeamos contra el fold de test para calcular accuracy\n",
    "    kf_y_pred     = arbol.predict(kf_X_test)\n",
    "    kf_y_pred_dev = arbol.predict(kf_X_train)\n",
    "        \n",
    "    # Calculamos accuracy\n",
    "    accuracy_validation.append(get_accuracy(kf_y_pred, kf_y_test) )\n",
    "    accuracy_train.append(get_accuracy(kf_y_pred_dev, kf_y_train) )\n",
    "\n",
    "    # Testeamos contra el fold de test para calcular el score roc\n",
    "    kf_y_pred_proba     = arbol.predict_proba(kf_X_test)\n",
    "    kf_y_pred_dev_proba = arbol.predict_proba(kf_X_train)\n",
    "    \n",
    "    # Calculamos roc score\n",
    "    roc_train.append(sklearn.metrics.roc_auc_score(kf_y_train, get_positive_class_probabilities(kf_y_pred_dev_proba)))\n",
    "    roc_validation.append(sklearn.metrics.roc_auc_score(kf_y_test, get_positive_class_probabilities(kf_y_pred_proba)))\n",
    "    \n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"]   = accuracy_train      # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracy_validation # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"]    = roc_train           # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"]  = roc_validation      # cambiar por aucs_validation\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "# df.plot(kind=\"bar\")\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con el arbol original podemos observar que el accuracy bajo considerablemente an algunos casos pasando de valores como 0.8111 a 0.5194 y manteniendose en otro relativamente cerca. Algo curioso sobre los resultados es el score AUC ROC, en algunos casos se vieron improvements mientras que en otros se mantuvo relativamente cerca al valor resultante de usar el arbol de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>0.6014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>0.7303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.8604   \n",
       "1             5                            Gini                       0.9527   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.8388   \n",
       "4             5         Ganancia de Información                       0.9439   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.7303  \n",
       "1                         0.6014  \n",
       "2                         0.6530  \n",
       "3                         0.7287  \n",
       "4                         0.7303  \n",
       "5                         0.6159  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training   = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "np.random.seed(SEED)\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        \n",
    "        arbol = MiClasificadorArbol(max_depth=altura, criterion=criterio)\n",
    "        arbol.fit(X_dev_np, y_dev_np)\n",
    "        \n",
    "        #Entrenamiento\n",
    "        y_pred = arbol.predict_proba(X_dev_np)\n",
    "        resultados_training.append( sklearn.metrics.roc_auc_score(y_dev_np, get_positive_class_probabilities(y_pred)))\n",
    "        \n",
    "        #Validacion\n",
    "        y_pred = arbol.predict_proba(X_eval_np)\n",
    "        resultados_validation.append( sklearn.metrics.roc_auc_score(y_eval_np, get_positive_class_probabilities(y_pred)))\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"]   = resultados_training# reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con el uso del arbol de sklearn podemos ver que el nuestro tiene valores muy similares. Esto nos da la pauta de que se pueden implementar modelos relativamente simples con resultados bastante razonables, siempre dependiendo del problema que se quiera resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "##############################################\n",
    "################# Auxiliares #################\n",
    "##############################################\n",
    "\n",
    "def top_resultados(grid, top=5):\n",
    "    print(\"Top {} combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=False).head(top))\n",
    "\n",
    "def bot_resultados(grid, bot=5):\n",
    "    print(\"Bot {} combinaciones\".format(bot))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=True).head(bot))\n",
    "    \n",
    "def correr_y_mostrar(estimator, parameters, folds, top):\n",
    "    grid = GridSearchCV(estimator, parameters, cv=folds, scoring='roc_auc')\n",
    "    time_before = time.time()\n",
    "    grid.fit(X_dev_np, y_dev_np)\n",
    "    time_after = time.time()\n",
    "    top_resultados(grid, top)\n",
    "    bot_resultados(grid, top)\n",
    "    runtime = (time_after - time_before) * 1000.0 \n",
    "    return (runtime, grid)\n",
    "\n",
    "# Para usar en caso de tener probabilidades a priori\n",
    "priors = [(0.1,0.9),(0.2,0.8),(0.3,0.7),(0.4,0.6),(0.5,0.5),(0.6,0.4),(0.7,0.3),(0.8,0.2),(0.9,0.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este algoritmo decidimos usar solo los atributos criterio y max_depth, ya que son los mas simples a la hora de explicar como se comportan y como afectas a los datos de entrenamiento.\n",
    "\n",
    "Sin embargo, al hacer algunas pruebas nos encontramos con otro parametro que nos parecio interesante, a continuacion hacemos los analisis en los dos casos (solo con criterio y max_depth | agregando el nuevo parametro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7531</td>\n",
       "      <td>0.8061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.8718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7299</td>\n",
       "      <td>0.8726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.8089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "1    entropy          2                 0.7531               0.8061\n",
       "2    entropy          3                 0.7388               0.8718\n",
       "3    entropy          4                 0.7312               0.9267\n",
       "52      gini          3                 0.7299               0.8726\n",
       "51      gini          2                 0.7287               0.8089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>0.5924</td>\n",
       "      <td>0.9972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>gini</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>gini</td>\n",
       "      <td>28</td>\n",
       "      <td>0.6035</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "59      gini         10                 0.5897               0.9994\n",
       "56      gini          7                 0.5924               0.9972\n",
       "55      gini          6                 0.5935               0.9922\n",
       "69      gini         20                 0.5954               1.0000\n",
       "77      gini         28                 0.6035               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>entropy</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>0.9503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>entropy</td>\n",
       "      <td>43</td>\n",
       "      <td>24</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>entropy</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.9539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>entropy</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>0.9538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth  min_samples_split  mean_score_validation  \\\n",
       "750    entropy         27                 24                 0.7597   \n",
       "137    entropy          5                 27                 0.7593   \n",
       "1198   entropy         43                 24                 0.7585   \n",
       "979    entropy         35                 29                 0.7568   \n",
       "391    entropy         14                 29                 0.7566   \n",
       "\n",
       "      mean_score_training  \n",
       "750                0.9711  \n",
       "137                0.9503  \n",
       "1198               0.9711  \n",
       "979                0.9539  \n",
       "391                0.9538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>0.9926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>gini</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5968</td>\n",
       "      <td>0.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5970</td>\n",
       "      <td>0.9930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.9967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     criterion  max_depth  min_samples_split  mean_score_validation  \\\n",
       "1540      gini          6                  2                 0.5914   \n",
       "2325      gini         34                  3                 0.5930   \n",
       "1572      gini          7                  6                 0.5968   \n",
       "1541      gini          6                  3                 0.5970   \n",
       "1569      gini          7                  3                 0.5992   \n",
       "\n",
       "      mean_score_training  \n",
       "1540               0.9926  \n",
       "2325               1.0000  \n",
       "1572               0.9958  \n",
       "1541               0.9930  \n",
       "1569               0.9967  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametersDecisionTree = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':range(1,51)\n",
    "}\n",
    "\n",
    "(tiempo_decision_tree, grid_decision_tree) = correr_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree,\n",
    "    5,\n",
    "    5\n",
    ")\n",
    "\n",
    "parametersDecisionTree2 = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':range(1,51),\n",
    "    'min_samples_split':range(2, 30)\n",
    "}\n",
    "\n",
    "(tiempo_decision_tree_2, grid_decision_tree_2) = correr_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree2,\n",
    "    5,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo con dos parametros\n",
    "\n",
    "A priori se puede ver que los mejores vs peores resultados tienen profundidades maximas bastante distintas(A excepcion del peor elemento con altura 6, suponemos que fue una muy mala muestra que justo dio ese resultado). Entre los mejores arboles en promedio no superan los 5 niveles, mientras que en los peores suele estar alrededor del 14/15.\n",
    "\n",
    "Una cosa importante a remarcar es que en los peores arboles, el score del set de entrenamiento es bastante alto (y 1 en varios casos), mientras que en los mejores este baja un poco. Esto se da por la tendencia a overfittear  data rapidamente de estos arboles a medida que aparecen mas niveles (Las hipotesis que toma se vuelven casos mas particulares).\n",
    "\n",
    "Por como se dan los resultados pareciera que la entropia funciona un poco mejor que gini como criterio, pero suponemos que esto no necesariamente es asi en el caso general. \n",
    "\n",
    "### Agregando min_samples_split\n",
    "\n",
    "Podemos ver que con min_samples_split el arbol se limita a cortar un nodo si hay al menos esa cantidad de samples que caen en el. \n",
    "\n",
    "Teniendo lo anterior en cuenta podemos observar que los arboles que dieron los mejores resultados fueron los que tuvieron mayor profundidad y mayor cantidad de samples como minimo para separar un nodo. Nuestra suposicion es que al ser relativamente alta la cantidad minima de splitteo, esto evita overfittear sobre casos no muy normales en los datos y obtener profundidad sobre informacion que es relevante. Pero manteniendo un limite a la hora de crear hipotesis demasiado particulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este estimador solo tomamos las probabilidades a priori de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.8619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0.2, 0.8)</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.3, 0.7)</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0.4, 0.6)</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.8618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       priors  mean_score_validation  mean_score_training\n",
       "8  (0.9, 0.1)                 0.8222               0.8619\n",
       "0  (0.1, 0.9)                 0.8221               0.8616\n",
       "1  (0.2, 0.8)                 0.8221               0.8615\n",
       "2  (0.3, 0.7)                 0.8220               0.8616\n",
       "3  (0.4, 0.6)                 0.8220               0.8618"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0.5, 0.5)</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0.6, 0.4)</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.8620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0.8, 0.2)</td>\n",
       "      <td>0.8219</td>\n",
       "      <td>0.8619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0.3, 0.7)</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>0.8616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       priors  mean_score_validation  mean_score_training\n",
       "4  (0.5, 0.5)                 0.8218               0.8620\n",
       "5  (0.6, 0.4)                 0.8218               0.8620\n",
       "6  (0.7, 0.3)                 0.8219               0.8620\n",
       "7  (0.8, 0.2)                 0.8219               0.8619\n",
       "2  (0.3, 0.7)                 0.8220               0.8616"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametersNaiveBayes = {\n",
    "    'priors':priors\n",
    "}\n",
    "\n",
    "(tiempo_bayes, grid_bayes) = correr_y_mostrar(\n",
    "    GaussianNB(), \n",
    "    parametersNaiveBayes, \n",
    "    5, \n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de experimentar con el metodo de Naive Bayes medimos su performance con distintas probabilidades a priori de cada clase. Antes de revisar los resultados teniamos la hipotesis de que el metodo daría mejores resultados cuando las probabilidades a priori se acercaran a la inferidas de los datos de entrenamiento. Sin embargo tanto el score de entrenamiento como de validación resultaron variar muy poco a medida que cambiaban las priors, pese a haber experimentado con un rango bastante disperso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>31</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>31</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8349</td>\n",
       "      <td>0.8546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>18</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8346</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>24</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>0.8577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>30</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.8550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>0.8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.8316</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_neighbors   weights  mean_score_validation  mean_score_training\n",
       "61           31  distance                 0.8361               1.0000\n",
       "59           30  distance                 0.8361               1.0000\n",
       "60           31   uniform                 0.8349               0.8546\n",
       "35           18  distance                 0.8348               1.0000\n",
       "47           24  distance                 0.8346               1.0000\n",
       "46           24   uniform                 0.8341               0.8577\n",
       "58           30   uniform                 0.8340               0.8550\n",
       "49           25  distance                 0.8336               1.0000\n",
       "34           18   uniform                 0.8332               0.8599\n",
       "37           19  distance                 0.8316               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>weights</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.6531</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7126</td>\n",
       "      <td>0.9356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7162</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7512</td>\n",
       "      <td>0.9037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7621</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7711</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>0.8818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_neighbors   weights  mean_score_validation  mean_score_training\n",
       "0            1   uniform                 0.6531               1.0000\n",
       "1            1  distance                 0.6531               1.0000\n",
       "2            2   uniform                 0.7126               0.9356\n",
       "3            2  distance                 0.7162               1.0000\n",
       "4            3   uniform                 0.7512               0.9037\n",
       "5            3  distance                 0.7562               1.0000\n",
       "6            4   uniform                 0.7621               0.8928\n",
       "7            4  distance                 0.7711               1.0000\n",
       "8            5   uniform                 0.7748               0.8818\n",
       "9            5  distance                 0.7839               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametersKNN = {\n",
    "    'n_neighbors' : list(range(1, 32)),\n",
    "    'weights'     : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "(tiempo_KNN, grid_knn) = correr_y_mostrar(\n",
    "    KNeighborsClassifier(), \n",
    "    parametersKNN, \n",
    "    5, \n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de analizar la performance de KNN sobre nuestros datos destacamos 2 hiper-parametros que nos parecen escenciales para este algoritmo, que son la cantidad de vecinos mas cercanos a la instacia que se quiere clasificar, y la forma en la que se estima el peso que tiene cada uno de estos vecinos a la hora de decidir como clasificar la instacia. De este último hiper-parametro experimentamos con dos posibles formulas, una es la de considerar uniformente los pesos de los vecinos involucrados, de manera que cada uno tengo la misma influencia a la hora de decidir a que clase pertenece la nueva instancia; la otra fue considerar como de mayor peso a aquellos que se encontraran a menor distancia.\n",
    "\n",
    "Observamos que en el caso del score obtenido con el conjunto de entrenamiento, siempre se obtuvo una estimación perfecta (de 1) al considerar los pesos en funcion de su distancia. Entendemos que esto ocurre porque al intentar clasificar una instancia ya incluida en el modelo, la distancia con ella mismo al ser cero opaca a todo el resto de los vecinos considerados (sin importar cuantos de estos haya). En cambio tomando los pesos uniformemente, el voto del vecino que se encuentra a distancia cero vale lo mismo que el del resto, y en consecuencia no ocurre un overfitting tan contundente como en el caso anterior.\n",
    "\n",
    "En el caso del score de validacion notamos que al menos en un principio el parametro que mas diferencia aporta es la cantidad de vecinos. A medida que estos aumentan mayor es el score obtenido en ambas estimaciones de pesos, quizas un poco mejor (al menos en un principio) con pesos segun su distancia sobre los pesos uniformes. Sin embargo estas tendencias iniciales no parecen mantenerse a medida que aumenta la cantidad de vecinos, ambos algoritmos parecen mostrar un rendimiento similar. Otra cuestion que nos llamo la atención es que a veces clasificar viendo menor cantidad de vecinos parece funcionar igual o mejor que viendo mas de ellos, pese a que tiene menor información del entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000e-03</td>\n",
       "      <td>0.8443</td>\n",
       "      <td>0.9572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000e-04</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>0.8792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000e-05</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>0.8492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000e-15</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000e-10</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C  mean_score_validation  mean_score_training\n",
       "4  1.0000e-03                 0.8443               0.9572\n",
       "3  1.0000e-04                 0.8332               0.8792\n",
       "2  1.0000e-05                 0.8238               0.8492\n",
       "0  1.0000e-15                 0.8225               0.8448\n",
       "1  1.0000e-10                 0.8225               0.8448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0000e+00</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0000e-02</td>\n",
       "      <td>0.8117</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000e-15</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000e-10</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.8448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000e-05</td>\n",
       "      <td>0.8238</td>\n",
       "      <td>0.8492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            C  mean_score_validation  mean_score_training\n",
       "6  1.0000e+00                 0.7689               1.0000\n",
       "5  1.0000e-02                 0.8117               0.9952\n",
       "0  1.0000e-15                 0.8225               0.8448\n",
       "1  1.0000e-10                 0.8225               0.8448\n",
       "2  1.0000e-05                 0.8238               0.8492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametersSVM = {\n",
    "    'C':[1e-15, 1e-10, 1e-5, 1e-4, 1e-3, 1e-2, 1.0],\n",
    "}\n",
    "\n",
    "(tiempo_SVM, grid_svm) = correr_y_mostrar(\n",
    "    LinearSVC(), \n",
    "    parametersSVM, \n",
    "    5,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este algoritmo decidimos usar el parametro C. Este controla el nivel de tolerancia al clasificar erroneamente las muestras, con lo que un C chico generaria un hiperplano con margen mas grande, permitiendo asi una hipotesis mas simple. Por otro lado tomando un C grande, se achica el margen del hiperplano y forzando a clasificar mejor los datos de entrenamiento.\n",
    "\n",
    "En los resultados se puede ver que con valores grandes de C la muestra tiende a \"overfittearse\", mientras que con valores mas chicos el score de validacion es mas alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 1\n",
    "\n",
    "Para el primero probamos usar los parametros **svd**, **n_components** y **priori**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>priors</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.3, 0.7)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.8, 0.2)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components      priors solver  mean_score_validation  \\\n",
       "0              0  (0.1, 0.9)    svd                 0.7462   \n",
       "47             5  (0.3, 0.7)    svd                 0.7462   \n",
       "34             3  (0.8, 0.2)    svd                 0.7462   \n",
       "35             3  (0.9, 0.1)    svd                 0.7462   \n",
       "36             4  (0.1, 0.9)    svd                 0.7462   \n",
       "\n",
       "    mean_score_training  \n",
       "0                0.9931  \n",
       "47               0.9931  \n",
       "34               0.9931  \n",
       "35               0.9931  \n",
       "36               0.9931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>priors</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.8, 0.2)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.7462</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_components      priors solver  mean_score_validation  \\\n",
       "0              0  (0.1, 0.9)    svd                 0.7462   \n",
       "33             3  (0.7, 0.3)    svd                 0.7462   \n",
       "34             3  (0.8, 0.2)    svd                 0.7462   \n",
       "35             3  (0.9, 0.1)    svd                 0.7462   \n",
       "36             4  (0.1, 0.9)    svd                 0.7462   \n",
       "\n",
       "    mean_score_training  \n",
       "0                0.9931  \n",
       "33               0.9931  \n",
       "34               0.9931  \n",
       "35               0.9931  \n",
       "36               0.9931  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametros_LDA_svd = {\n",
    "    'solver'            :['svd'],\n",
    "    'priors'            :priors,\n",
    "    'n_components'      :[0, 1, 2, 3, 4, 5, 6],\n",
    "}\n",
    "\n",
    "(tiempo_LDA_svd, grid_lda_svd) = correr_y_mostrar(\n",
    "    LDA(),\n",
    "    parametros_LDA_svd,\n",
    "    5,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos llama la atencion que todos los scores den iguales variando los parametros (Algo parecido a lo que nos paso en **Naive Bayes**), lo que nos da dos suposiciones: \n",
    "- Por como funcione svd, el data set se comporta siempre igual\n",
    "- Hay algun tema con la técnica que hace que de siempre lo mismo.\n",
    "\n",
    "Fuera de esto, podemos ver que el score de training y validacón difieren bastante. A continuacón, vamos a probar con otros solvers para comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 2\n",
    "\n",
    "En este experimento vamos a usar el solver **lsqr** (cuadrados minimos), junto con **priors** y **shrinkage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>priors</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>7</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>6</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>10</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5847</th>\n",
       "      <td>13</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>18</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7224</th>\n",
       "      <td>16</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>11</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>8</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7061</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_components      priors shrinkage solver  mean_score_validation  \\\n",
       "3093             7  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "2634             6  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "1716             4  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "4470            10  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "5847            13  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "8142            18  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "4011             9  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "7224            16  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "4929            11  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "3552             8  (0.7, 0.3)    0.7061   lsqr                 0.8463   \n",
       "\n",
       "      mean_score_training  \n",
       "3093                0.941  \n",
       "2634                0.941  \n",
       "1716                0.941  \n",
       "4470                0.941  \n",
       "5847                0.941  \n",
       "8142                0.941  \n",
       "4011                0.941  \n",
       "7224                0.941  \n",
       "4929                0.941  \n",
       "3552                0.941  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>priors</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>6</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>13</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>4</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>8</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5049</th>\n",
       "      <td>12</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>19</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7803</th>\n",
       "      <td>18</td>\n",
       "      <td>(0.1, 0.9)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>lsqr</td>\n",
       "      <td>0.7682</td>\n",
       "      <td>0.9792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_components      priors shrinkage solver  mean_score_validation  \\\n",
       "0                1  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "2295             6  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "6426            15  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "5508            13  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "1377             4  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "459              2  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "3213             8  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "5049            12  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "8262            19  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "7803            18  (0.1, 0.9)       0.1   lsqr                 0.7682   \n",
       "\n",
       "      mean_score_training  \n",
       "0                  0.9792  \n",
       "2295               0.9792  \n",
       "6426               0.9792  \n",
       "5508               0.9792  \n",
       "1377               0.9792  \n",
       "459                0.9792  \n",
       "3213               0.9792  \n",
       "5049               0.9792  \n",
       "8262               0.9792  \n",
       "7803               0.9792  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probamos con n_components para reduccion pero no afecto\n",
    "shrinkage = np.linspace(0.1,1.0).tolist()\n",
    "shrinkage.append('auto')\n",
    "\n",
    "parametros_LDA_lsqr_eigen = {\n",
    "    \"solver\": [\"lsqr\"],\n",
    "    \"priors\": priors,\n",
    "    \"shrinkage\": shrinkage,\n",
    "    \"n_components\": range(1, 20)\n",
    "}\n",
    "\n",
    "(tiempo_LDA_lsqr_eigen, grid_lda) = correr_y_mostrar(\n",
    "    LDA(),\n",
    "    parametros_LDA_lsqr_eigen,\n",
    "    5,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 3\n",
    "\n",
    "En este último caso corremos el mismo experimento que antes con los **priors** y **shrinkage**, pero utilizando el solver **eigen**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>priors</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>2</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>6</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>9</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6766</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>14</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>5</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>10</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7684</th>\n",
       "      <td>17</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>11</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7225</th>\n",
       "      <td>16</td>\n",
       "      <td>(0.7, 0.3)</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.9355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_components      priors shrinkage solver  mean_score_validation  \\\n",
       "799              2  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "2635             6  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "4012             9  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "6766            15  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "6307            14  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "2176             5  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "4471            10  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "7684            17  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "4930            11  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "7225            16  (0.7, 0.3)    0.7245  eigen                  0.847   \n",
       "\n",
       "      mean_score_training  \n",
       "799                0.9355  \n",
       "2635               0.9355  \n",
       "4012               0.9355  \n",
       "6766               0.9355  \n",
       "6307               0.9355  \n",
       "2176               0.9355  \n",
       "4471               0.9355  \n",
       "7684               0.9355  \n",
       "4930               0.9355  \n",
       "7225               0.9355  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 10 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>priors</th>\n",
       "      <th>shrinkage</th>\n",
       "      <th>solver</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>13</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3162</th>\n",
       "      <td>7</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>14</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>17</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>2</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>15</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>3</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>6</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>12</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.9, 0.1)</td>\n",
       "      <td>0.1</td>\n",
       "      <td>eigen</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_components      priors shrinkage solver  mean_score_validation  \\\n",
       "5916            13  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "3162             7  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "6375            14  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "7752            17  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "867              2  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "6834            15  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "1326             3  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "2703             6  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "5457            12  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "408              1  (0.9, 0.1)       0.1  eigen                 0.7729   \n",
       "\n",
       "      mean_score_training  \n",
       "5916               0.9665  \n",
       "3162               0.9665  \n",
       "6375               0.9665  \n",
       "7752               0.9665  \n",
       "867                0.9665  \n",
       "6834               0.9665  \n",
       "1326               0.9665  \n",
       "2703               0.9665  \n",
       "5457               0.9665  \n",
       "408                0.9665  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shrinkage = np.linspace(0.1,1.0).tolist()\n",
    "shrinkage.append('auto')\n",
    "\n",
    "parametros_LDA_lsqr_eigen = {\n",
    "    \"solver\": [\"eigen\"],\n",
    "    \"priors\": priors,\n",
    "    \"shrinkage\": shrinkage,\n",
    "    \"n_components\": range(1, 20)\n",
    "}\n",
    "\n",
    "(tiempo_LDA_lsqr_eigen, grid_lda) = correr_y_mostrar(\n",
    "    LDA(),\n",
    "    parametros_LDA_lsqr_eigen,\n",
    "    5,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista se puede notar la diferencia con **svd** con respecto a **eigen** y **lsqr**. El peor score para estos dos últimos solvers es mejor que el mejor resultado conseguido usando **svd**. \n",
    "\n",
    "Por otro en el caso de **eigen** con respecto a **lsqr**, ambos solvers parecen funcionar igual de bien (tanto en validación como en entrenamiento), y en ambos casos los mejores resultados en validación se obtienen con probabilidades a priori de **(0.7, 0.3)**. Mientras que con **svd** no parece haber una mejor selección de priors tan clara.\n",
    "\n",
    "Algo importante a resaltar es el **shrinkage**. Los mejores resultados se obtuvieron con valores altos, mas especificamente con un **shrinkage** de alrededor del 0.7, con el que se reduce un poco el score en el set de entrenamiento pero el de validacion aumenta alrededor de un 0.08 comparado con los peores casos. Suponemos que esto es esperable ya que el volumen del dataset de entrenamiento no es muchas veces mas grande que la cantida de features, lo que entendemos que suele resultar en la necesidad de un valor de **shrinkage** considerable.\n",
    "\n",
    "### Correcciones para el RTP\n",
    "\n",
    "Investigamos sobre el parametro **shrinkage**, este parametro es el parametro de regulación de esta técnica de clasificación. Por lo que tenemos entendido a la hora de estimar la matriz de covarianza (en base al dataset de entrenamiento) podemos llegar a tener una matriz con valores poco representativos, ya sea por tener valores mucho más altos o más bajos que los de la matriz de covarianza objetivo. Esto ocurre especialmente si el tamaño del dataset no llega a ser lo suficientemente grande con respecto a la cantidad de atributos que los caracterizan. Por esto es que para la matriz de covarianza $\\Sigma$ se suele usar un estimador como por ejemplo $\\hat{\\Sigma} = (1 - \\lambda)\\Sigma + \\lambda I_{n}$ donde $\\lambda$ es el valor del parametro **shrinkage** el cual es un valor decimal entre 0 y 1. Este parametro **shrinkage** puede tomar también el valor $\\textit{auto}$ el cual significa que el **shrinkage** es calculado automaticamente por medio del metodo de Ledoit y Wolf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "- RandomizeSearchCV cuenta con el parametro **n_iter** para regular la cantidad de veces que prueba parametros random, esto lo vamos a usar a lo largo de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliares para correr randomized search\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "def correr_randomized_y_mostrar(estimator, parameters, folds, top,  iteraciones=None):\n",
    "    random_search = None\n",
    "    \n",
    "    if(iteraciones is None):\n",
    "        random_search = RandomizedSearchCV(estimator, parameters, cv=folds, scoring='roc_auc')\n",
    "    else:\n",
    "        random_search = RandomizedSearchCV(estimator, parameters, cv=folds, scoring='roc_auc', n_iter=iteraciones)\n",
    "        \n",
    "    time_before = time.time()\n",
    "    random_search.fit(X_dev_np, y_dev_np)\n",
    "    time_after = time.time()\n",
    "    runtime = (time_after - time_before) * 1000.0\n",
    "    \n",
    "    top_resultados(random_search, top)\n",
    "    bot_resultados(random_search, top)\n",
    "    \n",
    "    return (runtime, random_search)\n",
    "\n",
    "def verTiempo(original, random):\n",
    "    display(\"########### Timepos ###########\")\n",
    "    display(\"original: {:f}\".format(original))\n",
    "    display(\"random: {:f}\".format(random))\n",
    "    display(\"diferencia: {:f}\".format( np.absolute(original-random) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este experimento tomamos el arbol de decision con solo 2 parametros que discutimos en la primera parte del ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>0.8718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.9739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>entropy</td>\n",
       "      <td>56</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>entropy</td>\n",
       "      <td>18</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "32   entropy          3                 0.7423               0.8718\n",
       "40   entropy          5                 0.7233               0.9739\n",
       "78   entropy        120                 0.6996               1.0000\n",
       "81   entropy         56                 0.6944               1.0000\n",
       "92   entropy         18                 0.6930               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5910</td>\n",
       "      <td>0.9923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>gini</td>\n",
       "      <td>48</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6067</td>\n",
       "      <td>0.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.9985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>102</td>\n",
       "      <td>0.6082</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "64      gini          6                 0.5910               0.9923\n",
       "49      gini         48                 0.6014               1.0000\n",
       "59      gini          7                 0.6067               0.9969\n",
       "12      gini          8                 0.6077               0.9985\n",
       "3       gini        102                 0.6082               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'########### Timepos ###########'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'original: 27282.335520'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'random: 35105.968237'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'diferencia: 7823.632717'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>entropy</td>\n",
       "      <td>83</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.9323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>entropy</td>\n",
       "      <td>197</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.7654</td>\n",
       "      <td>0.9309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>entropy</td>\n",
       "      <td>152</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>entropy</td>\n",
       "      <td>103</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.7642</td>\n",
       "      <td>0.9486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>entropy</td>\n",
       "      <td>75</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion  max_depth  min_samples_split  mean_score_validation  \\\n",
       "238   entropy         83             0.1184                 0.7654   \n",
       "182   entropy        197             0.1249                 0.7654   \n",
       "58    entropy        152             0.1056                 0.7644   \n",
       "439   entropy        103             0.0849                 0.7642   \n",
       "219   entropy         75             0.1092                 0.7634   \n",
       "\n",
       "     mean_score_training  \n",
       "238               0.9323  \n",
       "182               0.9309  \n",
       "58                0.9441  \n",
       "439               0.9486  \n",
       "219               0.9433  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>gini</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>gini</td>\n",
       "      <td>125</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>gini</td>\n",
       "      <td>175</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.6285</td>\n",
       "      <td>0.9968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>gini</td>\n",
       "      <td>78</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.6310</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>gini</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>0.9994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    criterion  max_depth  min_samples_split  mean_score_validation  \\\n",
       "152      gini         25             0.0076                 0.6119   \n",
       "262      gini        125             0.0020                 0.6140   \n",
       "316      gini        175             0.0312                 0.6285   \n",
       "79       gini         78             0.0190                 0.6310   \n",
       "350      gini         34             0.0187                 0.6312   \n",
       "\n",
       "     mean_score_training  \n",
       "152               1.0000  \n",
       "262               1.0000  \n",
       "316               0.9968  \n",
       "79                0.9994  \n",
       "350               0.9994  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'########### Timepos ###########'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'original: 746734.536886'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'random: 86889.745951'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'diferencia: 659844.790936'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametersDecisionTree = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':randint(1, 200)\n",
    "}\n",
    "\n",
    "(tiempo_random_decision_Tree, random_decision) = correr_randomized_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree,\n",
    "    5,\n",
    "    5,\n",
    "    100\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_decision_tree, tiempo_random_decision_Tree)\n",
    "\n",
    "parametersDecisionTree2 = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':randint(1, 200),\n",
    "    'min_samples_split':uniform(0, 1)\n",
    "}\n",
    "\n",
    "(tiempo_random_decision_Tree_2, random_decision_tree_2) = correr_randomized_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree2,\n",
    "    5,\n",
    "    5,\n",
    "    500\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_decision_tree_2, tiempo_random_decision_Tree_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser un espacio de busqueda discreto, grid y random search ven los mismos elementos en general. Usando un rango mas grande de elementos en la busqueda aleatoria sobre max_depth, podemos observar que las alturas optimas siguen estando cerca de los primeros valores.\n",
    "\n",
    "Con respecto a los tiempos de ejecucion:\n",
    "\n",
    "#### Experimento 1\n",
    "En los experimentos random tarda casi lo mismo por la cantidad de iteriaciones que tenemos (100). Por otro lado, la cantidad de combinaciones del experimento original eran 100 aprox(2 criterios + 50(aprox) profundidadez).\n",
    "\n",
    "#### Experimento 2\n",
    "Estos son mas largos en los experimentos random por la cantidad de iteraciones que usamos (500). Esto nos parecio razonable dada la cantidad de combinaciones que se generaban entre **max_depth** y **min_samples_split**. Con una cantidad pequena la version random se hubiera ejecutado mucho mas rapido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The total space of parameters 9 is smaller than n_iter=10. For exhaustive searches, use GridSearchCV.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-25d796c53f8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mparametersNaiveBayes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-275e536aceac>\u001b[0m in \u001b[0;36mcorrer_randomized_y_mostrar\u001b[0;34m(estimator, parameters, folds, top, iteraciones)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtime_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtime_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_after\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_before\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Regenerate parameter iterable for each fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mcandidate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m         \u001b[0mn_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0;34m\"The total space of parameters %d is smaller \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0;34m\"than n_iter=%d. For exhaustive searches, use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \"GridSearchCV.\" % (grid_size, self.n_iter))\n\u001b[0m\u001b[1;32m    251\u001b[0m             for i in sample_without_replacement(grid_size, self.n_iter,\n\u001b[1;32m    252\u001b[0m                                                 random_state=rnd):\n",
      "\u001b[0;31mValueError\u001b[0m: The total space of parameters 9 is smaller than n_iter=10. For exhaustive searches, use GridSearchCV."
     ]
    }
   ],
   "source": [
    "parametersNaiveBayes = {\n",
    "    'priors':priors\n",
    "}\n",
    "\n",
    "(tiempo_random_bayes, random_bayes) = correr_randomized_y_mostrar(\n",
    "    GaussianNB(), \n",
    "    parametersNaiveBayes, \n",
    "    5, \n",
    "    5\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_bayes, tiempo_random_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que todos los valores siguen dando el mismo resultado. Pareciera ser un bug en sklearn, por esto no seguimos con el experimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "Tomamos como parametro aleatorio la distribucion de todos los vecinos posibles que se pueden tomar (a los sumo 360)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "parametersKNN = {\n",
    "    'n_neighbors' : randint(1, 360),\n",
    "    'weights'     : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "(tiempo_random_KNN, random_knn) = correr_randomized_y_mostrar(\n",
    "    KNeighborsClassifier(), \n",
    "    parametersKNN, \n",
    "    5, \n",
    "    10,\n",
    "    200\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_KNN, tiempo_random_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso podemos ver que extendiendo el rango de los posibles vecinos encontramos mejores combinaciones. \n",
    "\n",
    "Algo que podemos decir es que esto es muy util en caso de no tener poder de computo suficiente o tiempo disponible para correr experimentos grandes con rangos extensos de datos. En este caso una busqueda randomizada probablemente provea una buena solucion con un costo mucho menor.\n",
    "\n",
    "Podemos ver que tardo mas tiempo en correr, de vuelta, por la cantidad de iteraciones que usamos (200) en comparacion con las 720 combinaciones posibles que habia. Pero, de nuevo, sigue siendo mucho mas rapido que haberlo ejecutado contra la cantidad original con una cantidad razonable de iteraciones."
   ]
  },
  {
   "attachments": {
    "imagen.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "Para este experimento vamos a retocar el parametro **C**. Como vimos que el score de validacion tiende a mejorar cerca del 0, usamos una distribucion gamma cerca de ese valor (para tener muchas muestras pequnas cercanas al 0). \n",
    "\n",
    "A modo de ejemplo(Extraido de [aqui](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html)), esto es algo de la forma:\n",
    "![imagen.png](attachment:imagen.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "parametersSVM = {\n",
    "    'C':gamma(a=1.0, loc=0, scale=0.001)\n",
    "}\n",
    "\n",
    "(tiempo_random_SVM, grid_svm) = correr_randomized_y_mostrar(\n",
    "    LinearSVC(),\n",
    "    parametersSVM,\n",
    "    5,\n",
    "    5,\n",
    "    30\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_SVM, tiempo_random_SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que los peores valores obtenidos (si bien usan un C mas cercano al 0 que los mejores) tienden a overfittear el conjunto de train y a no performar tan bien en el de validacion. Esto es, estan tomando un hiperplano tal que permite tan pocas malclasificaciones que termina overfitteando al entrenar. \n",
    "\n",
    "Por otro lado, los mejores valores de C tienen score un poco mejor que los que teniamos en el experimento sin Random Search. Esto es, random search nos ayudo a encontrar valores que no estabamos teniendo en cuenta.\n",
    "\n",
    "Hablando de los tiempos de ejecucion, estos tardaron mucho mas en el caso random. Esto es por las 30 iteraciones que le dimos (en comparacion a 7 valores que usamos en el experimento comun). Sin embargo comparando la escala es solo el doble de tiempo para casi 5 veces mas pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "Para este experimento tomamos de manera aleatoria la cantidad de componentes usada w\n",
    "\n",
    "#### Experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersLDA_svd = {\n",
    "    'solver'            :['svd'],\n",
    "    'priors'            :priors,\n",
    "    'n_components'      :randint(1, 300),\n",
    "}\n",
    "\n",
    "(tiempo_random_LDA_svd, random_lda_svd) = correr_randomized_y_mostrar(\n",
    "    LDA(),\n",
    "    parametersLDA_svd,\n",
    "    5,\n",
    "    5,\n",
    "    30\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_LDA_svd, tiempo_random_LDA_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nos pasa algo parecido a Naive Bayes. Si bien probamos con varios parametros, los scores siempre son iguales. Asumimos que es un bug de sklearn y no continuamos con este experimento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimento 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersLDA = {\n",
    "    \"solver\": [\"lsqr\", \"eigen\"],\n",
    "    \"priors\": priors,\n",
    "    \"shrinkage\": uniform(0.1, 0.9),\n",
    "    \"n_components\": randint(1, 400)\n",
    "}\n",
    "\n",
    "(tiempo_random_LDA_lsqr_eigen, grid_lda) = correr_randomized_y_mostrar(\n",
    "    LDA(),\n",
    "    parametersLDA,\n",
    "    5,\n",
    "    10,\n",
    "    10\n",
    ")\n",
    "\n",
    "verTiempo(tiempo_LDA_lsqr_eigen, tiempo_random_LDA_lsqr_eigen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este experimento podemos ver el potencial de usar la busqueda aleatoria en un espacio de parametros extenso. Usando una cantidad de **componentes** grande y **shrinkage** relativamente pequeno, el predictor da buenos resultados en tan solo unas pocas iteraciones. Ademas, esto lo hace en un tiempo aproximadamente 80 veces mas rapido que con la busqueda exhaustiva. Aun mas, la busqueda exhaustiva mira un subconjunto de los valores de los parametros utilizados, esto demuestra el potencial de **RandomizedSearch** para algunos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**Obs**: En este ejercicio nos falta comparar random forest y gradient boosting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Roc Auc Score\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std  = np.std(train_scores, axis=1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis=1)\n",
    "    test_scores_std   = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator, X, y, param, paramRange, plotTitle, parametroName):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=param, param_range=paramRange,\n",
    "        cv=5, scoring=\"roc_auc\")\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std  = np.std(train_scores, axis=1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis=1)\n",
    "    test_scores_std   = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(plotTitle)\n",
    "    plt.xlabel(parametroName)\n",
    "    plt.ylabel(\"Roc Auc Score\")\n",
    "    lw = 2\n",
    "    \n",
    "    plt.semilogx(paramRange, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"red\", lw=lw)\n",
    "    plt.fill_between(paramRange, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"red\", lw=lw)\n",
    "    plt.semilogx(paramRange, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"blue\", lw=lw)\n",
    "    plt.fill_between(paramRange, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"blue\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeras curvas de complejidad\n",
    "\n",
    "Veamos como se comportan las curvas para los parametros de ambos estimadores.\n",
    "\n",
    "**Nota:** Para el arbol de decision usamos el primero que habiamos probado ya que tiene mejor score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = grid_svm.best_estimator_\n",
    "plot_validation_curve(svm,X_dev_np, y_dev_np, \"C\", [pow(10,x/2) for x in range(-12,0)],\n",
    "                      \"Curvas para SVM\", \"C\")\n",
    "\n",
    "\n",
    "plot_validation_curve(svm,X_dev_np, y_dev_np, \"C\", [pow(10,x/2) for x in range(-10,-4)],\n",
    "                      \"Curvas para SVM\", \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este gráfico se observa como el score de entrenamiento y validación se mantienen en un valor mas o menos constante hasta cierto punto en el que el primero comienza a mejorar bruscamente y el segundo decae. Recordemos que conforme aumenta C también aumenta el interes en ajustar el hiperplano de manera de mejorar la presición y no tanto en perseguir un posible hiperplano que maximice el margen de separación. Esto da lugar a un sobreajuste en el caso de que C se vuelva suficientemente grande, lo que produce que el modelo se construya sobra una hipotesis mas rígida y por ende se alcance un sesgo alto. En consecuencia si bien como resultado conseguimos un score de entrenamiento alto, por fruto del sobreajuste el score de validación se vuelve muy bajo. El mejor modelo parecería conseguirse con un C de aproximadamente 10^-3, en la que se consigue un buen score de entrenamiento, pero aun no se llega a sobreajustar, y el modelo mantiene una varianza decente y se maximiza el score de validación, que es lo que nos deja una pauta mas certera de como puede llegar a trabajar nuestro modelo en la realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm = grid_svm.best_estimator_\n",
    "plot_learning_curve(svm, \"Learning Curve SVM mejor segun GridSearch\", X_dev_np, y_dev_np, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en la curva de aprendizaje que no hay una tendencia tan marcada a mejorar la performance del modelo en validación, si no que mas bien decrece ligeramente. Esto último nos parece raro, sin embago a partir de aproximadamente las 275 muestras el modelo remonta un poco, lo que no nos deja una conclusion muy convincente si no mas bien la curiosidad ver que ocurriría si tuvieramos mas datos con los que entrenar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = grid_decision_tree.best_estimator_\n",
    "plot_validation_curve(decisionTree,X_dev_np, y_dev_np, \"max_depth\", range(1,25),\n",
    "                      \"Curvas para Decision Tree\", \"Profundidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observa como a medida que aumenta la profundidad del árbol aumentamos la performance en los datos de validación y por sobre todo la de los datos de entrenamiento. En un principio en donde ambas curvas son no decrecientes nos encontramos en una situación donde la profundidad no es tan grande y por lo tanto el sesgo tampoco lo es. Sin embargo a cierta profundidad el score en validacón decrece y comienza a ser mas erratico, en estas situación consideramos que nos encontramos en un escenario en la que la varianza es baja y el sesgo es muy alto. Esto también se evidencia en la alta performance que mantiene constante con respecto a los datos de entrenamiento, dando a entender que esta sobreajustando el modelo a ellos. Lo ideal parecería ser quedarnos con un árbol de altura entre aproximadamente 55 en donde el sesgo aun no crecio tanto y a su vez la varianza se mantiene en valores no tan chicos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Haciendo zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "decisionTree = grid_decision_tree.best_estimator_\n",
    "plot_validation_curve(decisionTree,X_dev_np, y_dev_np, \"max_depth\", range(1,10),\n",
    "                      \"Curvas para Decision Tree\", \"Profundidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar un zoom en los hiperparametros, podemos apreciar que la profundidad optima esta alrededor del 4. A partir de este valor se empieza a overfitear los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = random_decision_tree_2.best_estimator_\n",
    "plot_learning_curve(decisionTree, \"Learning Curve Decision Tree mejor segun GridSearch\", X_dev_np, y_dev_np, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de la curva de aprndizaje obtenida con SVM, en el caso del arbol de decision conseguimos un resultado mas alentador. Aqui se puede apreciar una tendencia mas contundente del score de validación y entrenamiento con respecto a la cantidad de datos utilizados. Esto nos lleva a sospechar fuertemente que podriamos llegar a conseguir un mejor modelo, tanto de mayor precision como de menor varianza, si tuvieramos mas datos con los que entrenar. Aunque como siempre bajo la suposicion de que estos datos sean representativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "plot_validation_curve(RandomForestClassifier(n_estimators=300),X_dev_np, y_dev_np,\n",
    "                      \"max_features\", range(1,201,10),\n",
    "                      \"Curvas para Random Forest con 300 arboles\", \"max_features\")\n",
    "\n",
    "plot_validation_curve(RandomForestClassifier(n_estimators=200),X_dev_np, y_dev_np,\n",
    "                      \"max_features\", range(1,201,10),\n",
    "                      \"Curvas para Random Forest con 200 arboles\", \"max_features\")\n",
    "\n",
    "plot_validation_curve(RandomForestClassifier(n_estimators=30),X_dev_np, y_dev_np,\n",
    "                      \"max_features\", range(1,201,10),\n",
    "                      \"Curvas para Random Forest con 30 arboles\", \"max_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta ocasion nos dedicamos a jugar con el metodo de ensamble de Random Forest, el objetivo era generar un ensamble de 200 árboles, y luego experimentar el impacto que tenia en él ir variando el hiperparametro \"max features\". Este hiperparametro en teoría cumple la funcion de definir la cantidad de atributos distintos que son posibles seleccionar de manera aleatoria. Recordemos que los arboles de Random Forest son generados tomando en cuenta solo un subconjunto de los atributos de los cuales se basa para construir la estructura arboria, y asi intentar obtener arboles mas variados ignorando posibles atributos que tengan demasiado peso. Por ende nos econtramos con un tradeoff sobre este hiperparametro, si es demasiado chico los arboles generados se basan en muy poco atributos, lo que genera menos presicion en el modelo. Pero por otra parte si se tiene un \"max features\" demasiado alto, este tecnica se empieza a parecer a la tecnica de bagging, en el que teniamos el problema de tener muchos arboles similares.\n",
    "\n",
    "Para poder tener un idea experimental de la relacion entre cantidad de árboles y la cantida de features maxima, decidimos generar la curva de complejidad correspondiente al caso de 30 y 300 árboles (además del caso pedido de 200). \n",
    "En cuanto a la cantidad de estimadores, por alguna razon de estos tres modelos no hay ninguno del cual podamos concluir a ciencia cierta que sea mucho mejor que los otros dos, es decir el resultado obtenido con 30 arboles del cual se esperaba no tener tanto score como en el 200, parece tener una performance similar. En lo correspondiente al hiperparametro \"max_features\" como es de esperarse, se consigue un mejor score a medida que este aumenta, aunque la mejora no es tan brusca como imaginabamos. Como era de esperarse para los tres modelos esta mejora para alguna cantidad de features permitidos (diferente para cada modelo) alcanza un valor en el que la varianza es muy alta y el score del modelo comienza a volverse erratico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrosRF = {\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None] + [1, 20, 50, 100, 150, 200],\n",
    "    \"max_depth\": [3, 6, 12],\n",
    "    \"min_samples_split\": [2, 6, 12],\n",
    "    \"n_estimators\": [10, 50, 120, 200]\n",
    "}\n",
    "\n",
    "(tiempo_random_forest, grid_random_forest) = correr_y_mostrar(\n",
    "    RandomForestClassifier(),\n",
    "    parametrosRF,\n",
    "    5,\n",
    "    5\n",
    ")\n",
    "\n",
    "randomForest = grid_random_forest.best_estimator_\n",
    "plot_learning_curve(randomForest, \"Learning Curve Random Forest Mejor segun GridSearch\", X_dev_np, y_dev_np, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto al aprendizaje del modelo en relación al volumen del conjunt de entrenamiento, lo primero que observamos es que el score de validación no mantiene una tendencia optimista hasta el final, como si ocurre en otros casos. Aqui se obtiene un marcado crecimiento hasta llegar a las 100 muestras, luego esta tendencia comienza a decaer, por lo que acompañado del hecho de que el score en entrenamiento se mantiene constante, resulta que la evidencia se nos muestra pesimista sobre que el aumentar el tamaño de nuestro dataset nos vaya a dar alguna mejoria, tanto con respecto a la precision del modelo como a la varianza del mismo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "parametrosGB = {\n",
    "    \"loss\": ['deviance', 'exponential'],\n",
    "    \"criterion\": ['mse', 'friedman_mse'],\n",
    "    \"learning_rate\": np.linspace(0.1,1,100),\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None] + [1, 20, 50, 100, 150, 200],\n",
    "    \"max_depth\": [3, 6, 12],\n",
    "    \"min_samples_split\": [2, 6, 12],\n",
    "    \"subsample\": [0.3, 0.5, 0.8, 0.9, 1.0],\n",
    "    \"n_estimators\": range(1,200)\n",
    "}\n",
    "(tiempo_gb, random_grid_gb) = correr_randomized_y_mostrar(\n",
    "    GradientBoostingClassifier(), \n",
    "    parametrosGB, \n",
    "    5, \n",
    "    5, \n",
    "    50\n",
    ")\n",
    "\n",
    "plot_learning_curve(\n",
    "    random_grid_gb.best_estimator_, \n",
    "    \"Curva de aprendizaje para gradient boosting\",\n",
    "    X_dev_np, \n",
    "    y_dev_np, \n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este algoritmo parece ser uno de los mas prometedores, asi que probamos con muchas combinaciones de hiperparametros esperando obtener un score en validacion notablemente mas alto que en los algoritmos anteriores. Si bien efectivamente conseguimos el score mas alto con respecto a los otros algorimos, no llegamos a conseguir una diferencia tan significativa con respecto a otros. Observando la curva de aprendizaje sospechamos que aumentar la cantidad de datos podría llegar a mejorar un poco la performance, pero no parece haber una tendencia de crecimiento tan marcada del score de validacion como para estar muy convencidos de obtener una mejora muy notable.\n",
    "\n",
    "Al comparar este algotimo con el de Random Forest en relacion al mejor score conseguido en validacion, que hay una ligera diferencia a favor de Gradient Boosting, pero no es tan marcada y sospechamos que puede deberse a que en este último probamos muchas mas variantes de hiperparametros, por lo que quizas con una busqueda mas exautiva en el caso de Random Forest podría habernos dado la misma performance. Con respecto a su comportamiento con respecto al crecimiento del conjunto de entrenamiento, podemos ver en base a los graficos de ambas curvas de aprendizaje, sospechamos que Random Forest no se favorecería con el aumento del conjunto de entrenamiento, pues parece que se estanca en rapido con un conjunto mas reducido. En cambio con Gradient Boosting, su creciemiento del score de validación parece mas alentador, dandonos la sospecha que en este caso si podría mejorar con mas muestras, aunque como ya dijimos no necesariamente signifique que podamos llegar a conseguir un score mucho mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencia\n",
    "\n",
    "Para esta competencia usamos nuestro mejor modelo. Este fue Gradient Boosting. A continuacion generamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_competencia = random_grid_gb.predict_proba(X_competencia)\n",
    "\n",
    "df = pd.DataFrame(index=range(501,5000))\n",
    "df['output'] = [round(x[1],4) for x in y_competencia]\n",
    "df.to_csv('lambda_null_y_competencia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
