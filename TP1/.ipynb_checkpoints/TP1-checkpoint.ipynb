{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 1 \n",
    "### Clasificación sobre datos simulados. \n",
    "\n",
    "## Introducción\n",
    "Para este trabajo, hemos creado una función generadora de minions. Sobre cada minion, hemos medido 200 características que representan habilidades que poseen en distintas tareas (relacionadas al Mal).  \n",
    "\n",
    "El doctor Nefario ha ideado una fórmula para determinar si un minion es o no apto para concretar su plan para conquistar el mundo. De esta manera ha etiquetado más de 500 minions. Lamentablemente, ha perdido dicha fórmula y necesita seguir decidiendo si nuevos minions son o no aptos para su macabro plan.\n",
    "\n",
    "Es por esto que nuestro objetivo será construir clasificadores que estimen lo mejor posible la probabilidad de que nuevos minions sean o no aptos para concretar el plan de conquista y así facilitarle las cosas al doctor Nefario.\n",
    "\n",
    "Por otra parte, ya que el doctor Nefario tuvo problemas con equipos que sobreestiman sus resultados, decidió guardarse varias etiquetas extra que no compartirá con nadie, y que luego utilizará para elegir al mejor equipo, al cual contratará para (de una vez por todas) conquistar el mundo. \n",
    "\n",
    "\n",
    "En concreto:\n",
    "\n",
    "Tendrán disponible una matriz de datos $X$ de $500$ filas en donde cada fila $x^{(i)}$ representa un vector de $200$ características de cada instancia. Es decir, $\\textbf{x}^{(i)} = x_1^{(i)}, \\dots, x_{200}^{(i)}$ con $i$ entre $1$ y $500$. Además, tendrán y, un vector de $500$ posiciones con dos posibles valores: $True$ y $False$. \n",
    "\n",
    "Por otra parte, tendrán disponibles más instancias de evaluación $X_{competencia}$ sin las respectivas etiquetas que utilizaremos para evaluar sus resultados. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREAMBULOS\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from IPython.display import display, HTML\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as  pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.svm\n",
    "\n",
    "#Para el ejercicio 2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "import sklearn.model_selection\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "# Ejercicio Opcional\n",
    "from arbolDeDecision import MiClasificadorArbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6   ...       193  \\\n",
       "index                                                           ...             \n",
       "0      1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1     -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2     -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3      0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4     -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "...       ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "495    0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "496    0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497    0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498    0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499    0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "          194     195     196     197     198     199  \n",
       "index                                                  \n",
       "0     -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1     -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2      0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3     -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4     -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "495   -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "496    0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497    0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498    0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499   -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[500 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       output\n",
       "index        \n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           1\n",
       "...       ...\n",
       "495         1\n",
       "496         0\n",
       "497         1\n",
       "498         0\n",
       "499         0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "X = pd.read_csv(\"X.csv\", index_col=\"index\")\n",
    "y = pd.read_csv(\"y.csv\", index_col=\"index\", dtype=int)  # Cargamos los valores booleanos (True y False)\n",
    "                                                        # como números (1 y 0) para facilitar el manejo luego. \n",
    "    \n",
    "X_competencia = pd.read_csv(\"X_competencia1.csv\", index_col=\"index\")\n",
    "y_competencia_ejemplo = pd.read_csv(\"y_competencia_ejemplo.csv\", index_col=\"index\")\n",
    "display(X)\n",
    "display(y)\n",
    "\n",
    "#pd.plotting.scatter_matrix(X, c=y, s=80, figsize=(15, 8), marker='o', alpha=.8);\n",
    "\n",
    "# Descomentar si quieren ver los datos para la competencia:\n",
    "# display(X_competencia) \n",
    "# display(y_competencia_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "### Separación de datos\n",
    "\n",
    "Contarán con una cantidad limitada de datos, por lo cual es importante tomar una buena decisión en el momento de empezar a utilizarlos. En este punto pedimos que evalúen cómo separar sus datos para desarrollo y para evaluación tomando en cuenta la competencia. \n",
    "\n",
    "Para poder tomar los datos de desarrollo y evaluación, desidimos utilizar la varianza de los atributos como una primera manera de discriminar los datos. notamos que la varianza de los datos era muy igual y muy pocos \"minions\" tenian una varianza \"grande\" (mayor a 1.2). Al momento de analizar los datos, descubrimos que si bien estabamos tomando una muestra del 10% de la población, esta muestra de evaluación, no contenia la misma proporción que la población total de datos. De esta manera, decidimos cambiar la forma de separar los datos y decidimos tomar un 10% de los datos positivos y un 10% de los datos negativos. Para poder hacer esto, tomamos la cantidad de datos Positivos y negativos, guardando en 2 listas, los indices de donde se encuentran. Una vez hecho esto, tomamos de forma random los indices correspondientes a los datos positivos y los datos negativos (guardandolos en una lista random_values).\n",
    "Una vez que guardamos los indices en una lista general, se avanza con la toma de los \"minions\" de desarrollo y de evaluación. si el indice del minion se encuentra en la lista random_values, se toma ese \"minion\" como un \"minion\" de evaluación, de lo contrario, se lo toma como un \"minion\" de desarrollo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49, 200)\n",
      "(451, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.1735</td>\n",
       "      <td>-0.1365</td>\n",
       "      <td>0.3381</td>\n",
       "      <td>-0.1623</td>\n",
       "      <td>-1.3036</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>-0.4719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6060</td>\n",
       "      <td>-1.2876</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>-0.1326</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>1.2842</td>\n",
       "      <td>-0.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0925</td>\n",
       "      <td>-0.0823</td>\n",
       "      <td>-0.6084</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.7526</td>\n",
       "      <td>0.6447</td>\n",
       "      <td>0.2969</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.9700</td>\n",
       "      <td>1.0375</td>\n",
       "      <td>-0.1229</td>\n",
       "      <td>-0.0218</td>\n",
       "      <td>-0.6091</td>\n",
       "      <td>-0.2073</td>\n",
       "      <td>-1.3618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0410</td>\n",
       "      <td>-0.5786</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>-1.0642</td>\n",
       "      <td>-0.0713</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.7058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8771</td>\n",
       "      <td>-1.5508</td>\n",
       "      <td>0.4705</td>\n",
       "      <td>-0.1252</td>\n",
       "      <td>-1.1654</td>\n",
       "      <td>-0.0512</td>\n",
       "      <td>0.4096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-1.1664</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.4753</td>\n",
       "      <td>0.1509</td>\n",
       "      <td>-0.5689</td>\n",
       "      <td>1.6498</td>\n",
       "      <td>-3.6855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8930</td>\n",
       "      <td>-0.6476</td>\n",
       "      <td>-1.3079</td>\n",
       "      <td>1.8917</td>\n",
       "      <td>0.4656</td>\n",
       "      <td>-0.5856</td>\n",
       "      <td>0.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.6676</td>\n",
       "      <td>-0.6319</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>-2.4054</td>\n",
       "      <td>-0.0345</td>\n",
       "      <td>-1.9188</td>\n",
       "      <td>-2.3079</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2216</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>-0.0308</td>\n",
       "      <td>-0.1745</td>\n",
       "      <td>1.4396</td>\n",
       "      <td>0.7998</td>\n",
       "      <td>0.2981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.4185</td>\n",
       "      <td>1.5703</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.6297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.4333</td>\n",
       "      <td>-1.6339</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>-0.1173</td>\n",
       "      <td>-1.2342</td>\n",
       "      <td>0.6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.0140</td>\n",
       "      <td>-0.5479</td>\n",
       "      <td>-0.4961</td>\n",
       "      <td>1.6373</td>\n",
       "      <td>-1.2774</td>\n",
       "      <td>1.1131</td>\n",
       "      <td>0.3265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.4359</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>1.2347</td>\n",
       "      <td>-0.5180</td>\n",
       "      <td>0.5923</td>\n",
       "      <td>0.1242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>-0.2324</td>\n",
       "      <td>-0.1033</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.3833</td>\n",
       "      <td>-0.1040</td>\n",
       "      <td>-1.5391</td>\n",
       "      <td>-0.2593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3915</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>-1.6790</td>\n",
       "      <td>0.4492</td>\n",
       "      <td>-0.1785</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>-1.0192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>-0.2628</td>\n",
       "      <td>2.0574</td>\n",
       "      <td>0.7443</td>\n",
       "      <td>-0.8999</td>\n",
       "      <td>-0.8903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7809</td>\n",
       "      <td>1.3304</td>\n",
       "      <td>-0.4460</td>\n",
       "      <td>-1.3756</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>0.4097</td>\n",
       "      <td>1.1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.2516</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>-1.1980</td>\n",
       "      <td>0.4577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>0.2476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5829</td>\n",
       "      <td>-0.5494</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>1.2182</td>\n",
       "      <td>0.1025</td>\n",
       "      <td>3.0034</td>\n",
       "      <td>-0.0344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6   ...       193  \\\n",
       "8   -1.1735 -0.1365  0.3381 -0.1623 -1.3036  0.8479 -0.4719   ...    0.6060   \n",
       "13   0.0925 -0.0823 -0.6084  0.9772  0.7526  0.6447  0.2969   ...   -1.9700   \n",
       "27   0.0410 -0.5786  0.7457 -1.0642 -0.0713  0.0480  0.7058   ...   -0.8771   \n",
       "33  -1.1664  0.9925  0.4753  0.1509 -0.5689  1.6498 -3.6855   ...   -0.8930   \n",
       "49   1.6676 -0.6319  0.9587 -2.4054 -0.0345 -1.9188 -2.3079   ...    1.2216   \n",
       "..      ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "478  0.4185  1.5703  0.2419  0.0638  0.2017  0.3286  0.6297   ...   -0.4333   \n",
       "484  0.0140 -0.5479 -0.4961  1.6373 -1.2774  1.1131  0.3265   ...    0.1763   \n",
       "487 -0.2324 -0.1033  0.6555  0.3833 -0.1040 -1.5391 -0.2593   ...   -0.3915   \n",
       "492  0.2105  0.3868 -0.2628  2.0574  0.7443 -0.8999 -0.8903   ...   -0.7809   \n",
       "495  0.2516  0.9375 -1.1980  0.4577  0.9287  0.5373  0.2476   ...    0.5829   \n",
       "\n",
       "        194     195     196     197     198     199  \n",
       "8   -1.2876  0.0193 -0.1326  0.9576  1.2842 -0.6784  \n",
       "13   1.0375 -0.1229 -0.0218 -0.6091 -0.2073 -1.3618  \n",
       "27  -1.5508  0.4705 -0.1252 -1.1654 -0.0512  0.4096  \n",
       "33  -0.6476 -1.3079  1.8917  0.4656 -0.5856  0.7060  \n",
       "49   0.0828 -0.0308 -0.1745  1.4396  0.7998  0.2981  \n",
       "..      ...     ...     ...     ...     ...     ...  \n",
       "478 -1.6339  0.7776  0.4887 -0.1173 -1.2342  0.6157  \n",
       "484  0.4359  0.2237  1.2347 -0.5180  0.5923  0.1242  \n",
       "487  0.2274 -1.6790  0.4492 -0.1785  0.2836 -1.0192  \n",
       "492  1.3304 -0.4460 -1.3756  0.8521  0.4097  1.1375  \n",
       "495 -0.5494  0.4607  1.2182  0.1025  3.0034 -0.0344  \n",
       "\n",
       "[49 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.4914</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>1.2429</td>\n",
       "      <td>1.5576</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1302</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.1983</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>1.5375</td>\n",
       "      <td>-0.7727</td>\n",
       "      <td>-0.1401</td>\n",
       "      <td>2.0871</td>\n",
       "      <td>-0.8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.2749</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>-1.3108</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>-0.5503</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>-0.4478</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.6446</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>-1.2374</td>\n",
       "      <td>-1.3291</td>\n",
       "      <td>-1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2243</td>\n",
       "      <td>-0.5710</td>\n",
       "      <td>-0.2712</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-1.0045</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>-1.4507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>-0.1989</td>\n",
       "      <td>-0.0393</td>\n",
       "      <td>-0.5866</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>1.4925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5853</td>\n",
       "      <td>-0.8532</td>\n",
       "      <td>-0.2723</td>\n",
       "      <td>-0.5493</td>\n",
       "      <td>-2.9824</td>\n",
       "      <td>-0.1697</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6488</td>\n",
       "      <td>-0.7363</td>\n",
       "      <td>-0.8866</td>\n",
       "      <td>-1.2717</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>0.2007</td>\n",
       "      <td>-1.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.4155</td>\n",
       "      <td>1.4187</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>-0.7993</td>\n",
       "      <td>0.2939</td>\n",
       "      <td>-0.1796</td>\n",
       "      <td>-0.7140</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1314</td>\n",
       "      <td>-0.4230</td>\n",
       "      <td>-0.2685</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>-1.2245</td>\n",
       "      <td>-1.9421</td>\n",
       "      <td>1.5186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.2680</td>\n",
       "      <td>-0.5540</td>\n",
       "      <td>-1.5096</td>\n",
       "      <td>0.4621</td>\n",
       "      <td>-0.2984</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>-1.6079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3474</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>-0.2941</td>\n",
       "      <td>-0.4827</td>\n",
       "      <td>-0.2835</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>1.7427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.6246</td>\n",
       "      <td>-1.0590</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>-1.6657</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1075</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>-0.4229</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>-0.0808</td>\n",
       "      <td>-1.7054</td>\n",
       "      <td>-0.4786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.7154</td>\n",
       "      <td>0.3542</td>\n",
       "      <td>-0.9023</td>\n",
       "      <td>-1.7792</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8491</td>\n",
       "      <td>0.7469</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>-1.0090</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>-1.7513</td>\n",
       "      <td>-0.5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>1.7056</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>-0.8350</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0130</td>\n",
       "      <td>0.1483</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>-1.6642</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>-0.0118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.4028</td>\n",
       "      <td>-0.6085</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>-0.8598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3121</td>\n",
       "      <td>-0.7630</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.6161</td>\n",
       "      <td>-0.0902</td>\n",
       "      <td>-1.0215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6   ...       193  \\\n",
       "0    1.4914  0.1644  1.2315  1.2429  1.5576  0.0455  0.1302   ...   -1.1983   \n",
       "1   -0.2749  0.2780 -1.3108  0.6801 -0.5503  0.6359 -0.4478   ...    1.2190   \n",
       "2   -0.2243 -0.5710 -0.2712 -0.1328 -1.0045  0.9315 -1.4507   ...    0.9459   \n",
       "3    0.5853 -0.8532 -0.2723 -0.5493 -2.9824 -0.1697 -0.0430   ...    1.6488   \n",
       "4   -1.4155  1.4187  0.6027 -0.7993  0.2939 -0.1796 -0.7140   ...    1.1314   \n",
       "..      ...     ...     ...     ...     ...     ...     ...   ...       ...   \n",
       "494  0.2680 -0.5540 -1.5096  0.4621 -0.2984  0.2462 -1.6079   ...   -0.3474   \n",
       "496  0.6246 -1.0590  0.9491  0.2687  0.6610 -1.6657  0.3982   ...   -0.1075   \n",
       "497  0.2677  0.1802  0.7154  0.3542 -0.9023 -1.7792 -0.0121   ...    0.8491   \n",
       "498  0.1926  0.7834  1.7056  0.3418 -0.8350  0.4068  0.0495   ...   -0.0130   \n",
       "499  0.0427  0.4028 -0.6085  1.0845  0.1033  0.2698 -0.8598   ...   -0.3587   \n",
       "\n",
       "        194     195     196     197     198     199  \n",
       "0   -0.0118  1.5375 -0.7727 -0.1401  2.0871 -0.8312  \n",
       "1   -0.3190 -0.6446 -0.0061 -1.2374 -1.3291 -1.3265  \n",
       "2    0.1430 -0.1989 -0.0393 -0.5866  2.2507  1.4925  \n",
       "3   -0.7363 -0.8866 -1.2717 -0.1493  0.2007 -1.4820  \n",
       "4   -0.4230 -0.2685  0.3045 -1.2245 -1.9421  1.5186  \n",
       "..      ...     ...     ...     ...     ...     ...  \n",
       "494  0.0460 -0.2941 -0.4827 -0.2835  0.9839  1.7427  \n",
       "496  0.8993 -0.4229  0.3977 -0.0808 -1.7054 -0.4786  \n",
       "497  0.7469  0.2071 -1.0090  0.3317 -1.7513 -0.5397  \n",
       "498  0.1483  0.5019 -0.0020 -1.6642  2.5117 -0.0118  \n",
       "499 -0.3121 -0.7630  0.6525  0.6161 -0.0902 -1.0215  \n",
       "\n",
       "[451 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAADFCAYAAADOrZB2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADttJREFUeJzt3X+sZHV5x/H3p/ijaVXAsooB7EWCsNa1S7uhJkSrohZxA9rULrSltNrQTSARf6Rd6h/dNDExmpWmkWKgEtcUVFokkoKt212iNilWFtdVuqBAURe2C2qqJjY2C0//mHNxgLt7586cMzN35v1KNnfmO2fmPJPd/dzz63ueVBWSNO9+btIFSNI0MAwlCcNQkgDDUJIAw1CSAMNQkgDDUJIAw1CSAMNQkgB4xnILJLkO2Ag8UlUvb8Y+DZzWLHIM8D9VtT7JArAPuLd57Y6q2rzcOo477rhaWFhYcfGSdCS7d+/+XlWtGWTZZcMQ+DjwEeATiwNVtWnxcZJtwA/7lr+/qtYPVmrPwsICd95550reIknLSvLtQZddNgyr6ovNFt9SKwrwu8DrBl2hJE2jUY8Zvgo4WFXf6hs7OclXk3whyasO98YklyS5M8mdjz766IhlSNJoRg3DC4FP9j0/ALy4qs4A3g3ckOR5S72xqq6pqg1VtWHNmoF26SWpM0OHYZJnAL8NfHpxrKp+WlXfbx7vBu4HXjpqkZLUtVG2DF8P3FNV+xcHkqxJclTz+CXAqcADo5UoSd1bNgyTfBL4d+C0JPuTvKN56QKevIsM8Gpgb5KvAf8IbK6qH7RZsCR1YZCzyRceZvyPlhi7Cbhp9LIkabycgSJJGIaSBBiGkgQYhpIEGIaaE1u3bp10CZpyhqEkYRhKEmAYShJgGEoSYBhKEmAYShJgGEoSYBhKEmAYqkPH375n0iVIAxvkfobXJXkkyTf6xrYmeSjJnubPuX2vXZHkviT3JvmtrgqXpDYNsmX4ceCcJcavrKr1zZ/bAJK8jN5NX3+lec/fLt75WmrbwpZbV7T8/i1f6qgSzYJlw7CqvggMerfq84FPNb1Q/gu4DzhzhPo0Y5wjrGk1yjHDy5LsbXajj23GTgC+27fM/mbsaWwVqjYcbutw565TxlyJVrthw/Bq4BRgPb32oNua8SyxbC31AbYKVReGPWlz1eZdLVei1WaoMKyqg1X1WFU9DlzLz3aF9wMn9S16IvDwaCVKw3O3XIMaKgyTvKjv6VuBxTPNtwAXJHl2kpPptQr9j9FK1KwYVzC5i6xhLNsdr2kV+hrguCT7gb8EXpNkPb1d4AeBPwWoqruT3Aj8J3AIuLSqHuumdOnIeqF40aTL0CoxbKvQjx1h+fcD7x+lKEkaN2egaO558kRgGEpPMBTnm2GoubRt08ZJl6ApYxiqE96kQauNYShJGIaaASu9YYO0FMNQM8Hdco3KMNTEjOuWWv0zX7yNlw7HMFTnRpket+/0tS1W8mSeUVY/w1CSMAw1YW6daVoYhppKXe4eS0sxDDURnsjQtDEMNRbD3MvQrUON07CtQj+U5J6mB8rNSY5pxheS/G9fC9GPdlm8ZsO2TRufOHY4ys0SBr3WsH+r1GOWWjRsq9AdwMur6hXAN4Er+l67v6+F6OZ2ypSkbg3VKrSqPl9Vh5qnd9DrdSINxOOFmkZtHDN8O/C5vucnJ/lqki8kedXh3mSrUEnTZKQwTPI+er1Orm+GDgAvrqozgHcDNyR53lLvtVWopGkydBgmuRjYCPx+VRVAVf20qr7fPN4N3A+8tI1CJalLw7YKPQf4c+C8qvpJ3/iaJEc1j19Cr1XoA20Uqvnh7fc1CcO2Cr0CeDawIwnAHc2Z41cDf5XkEPAYsLmqfrDkB2su2MNYq0WrrUKr6ibgplGLkqRxcwaKJGEYShJgGEoSYBhKEmAYShJgGGoVWLd93aRL0BwwDCUJw1CSAMNQkgDDUJIAw1CSAMNQkgDDUFPEW3dpkgYKw8N0yHt+kh1JvtX8PLYZT5K/SXJf0z3v17oqXpLaMuiW4cd5eoe8LcDOqjoV2Nk8B3gTvZu6ngpcAlw9epmS1K2BwnCpDnnA+cD25vF24C1945+onjuAY5K8qI1iJakroxwzfGFVHQBofr6gGT8B+G7fcvubsSexO56kadLFCZQsMVZPG7A7nqQpMkoYHlzc/W1+PtKM7wdO6lvuRODhEdYjSZ0bJQxvAS5uHl8MfLZv/A+bs8qvBH64uDstSdNq2YZQcNgOeR8AbkzyDuA7wNuaxW8DzgXuA34C/HHLNUtS6wYKw8N0yAM4e4llC7h0lKIkadycgSJJGIaSBBiG0mC2Hj3pCtQxw1Bqwc5dp0y6BI3IMJTGZNumjZMuQUdgGEqDcld5phmGkoRhKC3PLcK5YBhKEoahtCILW24deNmtW7d2V4haZxhKIzj+9j2TLkEtMQwlCcNQkgDDUJKAEcIwyWlJ9vT9+VGSy5NsTfJQ3/i5bRYsTSun5K1uQ4dhVd1bVeuraj3w6/Ru5Hpz8/KVi69V1W1tFCpNk/6zyoOcRNm/5UtdlqMWtLWbfDZwf1V9u6XPk1Y1L6tZfdoKwwuAT/Y9vyzJ3iTXJTl2qTfYKlTSNBk5DJM8CzgP+Idm6GrgFGA9cADYttT7bBUqaZq0sWX4JuCuqjoIUFUHq+qxqnocuBY4s4V1SKuWxwtXhzbC8EL6dpEXeyk33gp8o4V1SKuSQbh6jBSGSX4BeAPwmb7hDyb5epK9wGuBd42yDnXP/7DDcSrebBmoVejhVNVPgF96ythFI1UkSRPgDJQ5NMxlH/tOX9t+ITPIC69XL8NQK7Ju+7pJlyB1wjCccx4vbN+RtrxtCjW9DMM5c6TduG2bNvqfVXPLMJxTgxw3vGrzru4LkaaEYaglGYSaN4ahhjLPJ1JW0gdFq4dhqBWb5yBsg8dlp5NhqKfxP6vmkWEoSRiGGsDi7BNnoWiWGYaShGGoxuFmoniJjeaFYajhbT160hVIrWnjtv8PNvcv3JPkzmbs+Ul2JPlW83PJPiiaLJsWST/T1pbha5u2oBua51uAnVV1KrCzeS5JU6ur3eTzge3N4+3AWzpajyS1oo0wLODzSXYnuaQZe2FVHQBofr7gqW+yVaikaTLSbf8bZ1XVw0leAOxIcs8gb6qqa4BrADZs2FAt1CFJQxt5y7CqHm5+PgLcTK816MHFLnnNz0dGXY8kdWnU7ni/mOS5i4+BN9JrDXoLcHGz2MXAZ0dZjyR1bdTd5BcCNydZ/Kwbquqfk3wFuDHJO4DvAG8bcT2S1KlRW4U+APzqEuPfB84e5bMlaZycgSJJGIaSBBiGkgQYhpIEGIaSBBiGkgQYhpIEGIaSBBiGkgQYhpIEGIaSBBiGkgQYhpIEGIbSqrZz1ymTLmFmDB2GSU5KcnuSfUnuTvLOZnxrkoea1qF7kpzbXrmS1I1RtgwPAe+pqrXAK4FLk7ysee3KpnXo+qq6beQqJS3LPtijGToMq+pAVd3VPP4xsA84oa3CpHmz7/S1K1r++Nv3dFTJfGrlmGGSBeAM4MvN0GVJ9ia5Lsmxh3mPrUJX4KrNuyZdgqaUxw3bMXIYJnkOcBNweVX9CLgaOAVYDxwAti31vqq6pqo2VNWGNWvWjFqGJI1k1O54z6QXhNdX1WcAqupgVT1WVY8D19JrHSppGFuPXtnizXHD/Vu+1EExs22Us8kBPgbsq6oP942/qG+xt9JrHSpppVYYhBrNKFuGZwEXAa97ymU0H0zy9SR7gdcC72qjUD3duu3rJl2CxmRhy62TLmHmDd0qtKr+DcgSL3kpjdSmrUcDN7Cw5VYe/MCbl1ykdxLlorGWNWucgTJFPM4j6G3xH26rf3EL0ctq2mcYShKG4dRYavbAtk0bnza27/S1S1+c2xxs99iSFrmnsTKG4SqweMH1SmcoaPVp46SY0/KGYxhOGX+bazkeL+yGYTgLFq9H87o0aWiGoSRhGE6lQXaVF48teeG11A7DcAZ5RllaOcNwSi1eVrPU5TWS2mcYSjqiednTMAzHxMshNGtm7aayhqEkYRi2z2v9NOWe2kJi0CsSjr99z0zv4XQWhknOSXJvkvuSbOlqPV1b7gTGvtPXepmLVr3l7pLzVIu7yLM09a+TMExyFHAV8CbgZcCFfW1EV53+QOz/rTrMXOFZ/s2q1WPx327/v+EnAnHr0Svaw5mVQOxqy/BM4L6qeqCq/g/4FHB+R+s6spZ2W7dt2vhEEF61edeRg7D5x7Sw5da5OROn1edIdz86krZOnEzbnlSqqv0PTX4HOKeq/qR5fhHwG1V1Wd8ylwCXNE9PA+5tvZCe44DvdfTZ08jvO9vm7fvCaN/5l6tqoPabQ9/2fxlLtQN4UupW1TXANR2t/2eFJHdW1Yau1zMt/L6zbd6+L4zvO3e1m7wfOKnv+YnAwx2tS5JG1lUYfgU4NcnJSZ4FXADc0tG6JGlknewmV9WhJJcB/wIcBVxXVXd3sa4BdL4rPmX8vrNt3r4vjOk7d3ICRZJWG2egSBKGoSQBcxSGSd6bpJIcN+laupbkQ0nuSbI3yc1Jjpl0TV2YlSmfg0hyUpLbk+xLcneSd066pnFIclSSryb5p67XNRdhmOQk4A3AdyZdy5jsAF5eVa8AvglcMeF6WjdrUz4HcAh4T1WtBV4JXDrj33fRO4F941jRXIQhcCXwZzzlwu9ZVVWfr6pDzdM76F3nOWumZ8rnGFTVgaq6q3n8Y3oBccJkq+pWkhOBNwN/N471zXwYJjkPeKiqvjbpWibk7cDnJl1EB04Avtv3fD8zHg6LkiwAZwBfnmwlnftrehsxj49jZV1NxxurJP8KHL/ES+8D/gJ443gr6t6RvnNVfbZZ5n30dq+uH2dtY7LslM9ZlOQ5wE3A5VX1o0nX05UkG4FHqmp3kteMY50zEYZV9fqlxpOsA04GvpYEeruLdyU5s6r+e4wltu5w33lRkouBjcDZNZsXk87dlM8kz6QXhNdX1WcmXU/HzgLOS3Iu8PPA85L8fVX9QVcrnKuLrpM8CGyoqpm+60eSc4APA79ZVY9Oup4uJHkGvZNDZwMP0ZsC+nsTnOnUqfR+m28HflBVl0+6nnFqtgzfW1Wdtoqc+WOGc+ojwHOBHUn2JPnopAtqW3OCaHHK5z7gxlkNwsZZwEXA65q/0z3NVpNaMldbhpJ0OG4ZShKGoSQBhqEkAYahJAGGoSQBhqEkAYahJAHw/zYVfpfUZgVfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO 1. \n",
    "import random\n",
    "np.random.seed(1234)\n",
    "\n",
    "Xdev  = []\n",
    "Ydev  = []\n",
    "Xeval = []\n",
    "Yeval = []\n",
    "iPos  = []\n",
    "iNeg  = []\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    if y.loc[i].iloc[0] == 1:\n",
    "        iPos.append(i)\n",
    "    else: \n",
    "        iNeg.append(i)\n",
    "        \n",
    "\n",
    "random_Positives =random.sample(range(1, len(iPos)), int(len(iPos)/10))\n",
    "random_Negatives =random.sample(range(1, len(iNeg)), int(len(iNeg)/10))\n",
    "random_values= []\n",
    "\n",
    "for e in random_Positives:\n",
    "    random_values.append(iPos[e])\n",
    "for e in random_Negatives:\n",
    "    random_values.append(iNeg[e])  \n",
    "    \n",
    "for i in range(X.shape[0]):\n",
    "    if i in random_values:\n",
    "        Xeval.append(X.loc[i])\n",
    "        Yeval.append(y.loc[i])\n",
    "    else:\n",
    "        Xdev.append(X.loc[i])\n",
    "        Ydev.append(y.loc[i])\n",
    "\n",
    "X_dev, X_eval, y_dev, y_eval = pd.DataFrame(Xdev),pd.DataFrame(Xeval),pd.DataFrame(Ydev),pd.DataFrame(Yeval)\n",
    "        \n",
    "print(str(X_eval.shape))\n",
    "print(str(X_dev.shape))\n",
    "\n",
    "display(X_eval)\n",
    "display(X_dev)\n",
    "\n",
    "#Distribucion de los X de evaluacion\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(X_eval))\n",
    "plt.show()\n",
    "\n",
    "#Distribucion de los X de entrenamiento\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(np.array(X_dev))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "### Construcción de modelos\n",
    "\n",
    "Para este punto, la tarea consiste en construir y evaluar modelos de tipo árbol de decisión, de manera de obtener una estimación realista de la performance de los mismos. \n",
    "\n",
    "1. Entrenar un árbol de decisión con altura máxima 3 y el resto de los hiperparámetros en default. \n",
    "2. Estimar la performance del modelo utilizando K-fold cross validation con K = 5, con las métricas “Accuracy” y “ROC AUC”. Para ello, se pide medir la performance en cada partición tanto sobre el fold de validación como sobre los folds de entrenamiento. Luego, completar la primera tabla.\n",
    "3. Entrenar árboles de decisión para cada una de las siguientes combinaciones y completar la segunda tabla.\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA: Usar la implementación de árboles de decisión que realizaron para la guía de ejercicios de la materia. Adaptarla para que cumpla con la interfaz requerida por sklearn, asegurarse de que funcione con variables continuas y reproducir las tablas anteriores.   **\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Arbol de sklearn ###\n",
    "arbol = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "#######################\n",
    "### Ejercicio Extra ###\n",
    "#######################\n",
    "\n",
    "# Descomentar para usar este arbol \n",
    "#arbol = MiClasificadorArbol(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3> TABLA 1 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy (training)</th>\n",
       "      <th>Accuracy (validación)</th>\n",
       "      <th>AUC ROC (training)</th>\n",
       "      <th>AUC ROC (validación)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Permutación</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.7026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>0.6659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>0.5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8283</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.6561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.6111</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.6050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Accuracy (training)  Accuracy (validación)  AUC ROC (training)  \\\n",
       "Permutación                                                                   \n",
       "1                         0.8222                 0.7033              0.8212   \n",
       "2                         0.7950                 0.6556              0.7967   \n",
       "3                         0.8393                 0.5889              0.8397   \n",
       "4                         0.8283                 0.6556              0.8293   \n",
       "5                         0.8172                 0.6111              0.8116   \n",
       "\n",
       "             AUC ROC (validación)  \n",
       "Permutación                        \n",
       "1                          0.7026  \n",
       "2                          0.6659  \n",
       "3                          0.5775  \n",
       "4                          0.6561  \n",
       "5                          0.6050  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_training = []\n",
    "accuracies_validation = []\n",
    "aucs_training = []\n",
    "aucs_validation = []\n",
    "\n",
    "X_dev_np = np.array(X_dev)\n",
    "y_dev_np = np.array(y_dev).ravel()\n",
    "\n",
    "X_eval_np = np.array(X_eval)\n",
    "y_eval_np = np.array(y_eval).ravel()\n",
    "\n",
    "display(len(X_dev_np))\n",
    "display(y_dev_np)\n",
    "arbol.fit(X_dev_np, y_dev_np)\n",
    "\n",
    "def get_accuracy(y_pred, y_eval_np):\n",
    "    return np.mean(y_pred == y_eval_np)\n",
    "    \n",
    "def show_prediction_accuracy(y_pred, y_eval_np, x_eval_np):\n",
    "    print(\"Predicciones sobre el test set:\\n {}\".format(y_pred))\n",
    "    print(\"Score sobre el test set: {:.2f}\".format(np.mean(y_pred == y_eval_np))) # A mano\n",
    "    print(\"Score sobre el test set: {:.2f}\".format(arbol.score(x_eval_np, y_eval_np))) # usando el método score.\n",
    "\n",
    "#Generamos los 5 folds\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "accuracy_train      = []\n",
    "accuracy_validation = []\n",
    "roc_train      = []\n",
    "roc_validation = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_dev_np):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    kf_X_train, kf_X_test = X_dev_np[train_index], X_dev_np[test_index]\n",
    "    kf_y_train, kf_y_test = y_dev_np[train_index], y_dev_np[test_index]\n",
    "    \n",
    "    #Entrenamos el arbol con el fold actual\n",
    "    arbol.fit(kf_X_train, kf_y_train)\n",
    "    \n",
    "    #Testeamos contra el fold de test\n",
    "    kf_y_pred     = arbol.predict(kf_X_test)\n",
    "    kf_y_pred_dev = arbol.predict(kf_X_train)\n",
    "        \n",
    "    #Calculamos accuracy\n",
    "    accuracy_validation.append(get_accuracy(kf_y_pred, kf_y_test) )\n",
    "    accuracy_train.append(get_accuracy(kf_y_pred_dev, kf_y_train) )\n",
    "    \n",
    "    #Calculamos roc score\n",
    "    roc_train.append(sklearn.metrics.roc_auc_score(kf_y_train, kf_y_pred_dev))\n",
    "    roc_validation.append(sklearn.metrics.roc_auc_score(kf_y_test, kf_y_pred))\n",
    "    \n",
    "df = pd.DataFrame(index=range(1,6))\n",
    "df.index.name = \"Permutación\"\n",
    "                  \n",
    "df[\"Accuracy (training)\"]   = accuracy_train     # cambiar por accuracies_training\n",
    "df[\"Accuracy (validación)\"] = accuracy_validation  # cambiar por accuracies_validation\n",
    "df[\"AUC ROC (training)\"]    = roc_train      # cambiar por aucs_training\n",
    "df[\"AUC ROC (validación)\"]  = roc_validation    # cambiar por aucs_validation\n",
    "\n",
    "display(HTML(\"<h3> TABLA 1 </h3>\"))\n",
    "display(df)\n",
    "\n",
    "# Descomentar las siguientes líneas para graficar el resultado\n",
    "# df.plot(kind=\"bar\")\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3> TABLA 2 </h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Altura máxima</th>\n",
       "      <th>Criterio de evaluación de corte</th>\n",
       "      <th>AUC ROC promedio (training)</th>\n",
       "      <th>AUC ROC promedio (validación)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.6735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Gini</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>0.6531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Gini</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0.7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>0.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Inifinito</td>\n",
       "      <td>Ganancia de Información</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Altura máxima Criterio de evaluación de corte  AUC ROC promedio (training)  \\\n",
       "0             3                            Gini                       0.7982   \n",
       "1             5                            Gini                       0.9290   \n",
       "2     Inifinito                            Gini                       1.0000   \n",
       "3             3         Ganancia de Información                       0.7539   \n",
       "4             5         Ganancia de Información                       0.8803   \n",
       "5     Inifinito         Ganancia de Información                       1.0000   \n",
       "\n",
       "   AUC ROC promedio (validación)  \n",
       "0                         0.6735  \n",
       "1                         0.6531  \n",
       "2                         0.5714  \n",
       "3                         0.7551  \n",
       "4                         0.7143  \n",
       "5                         0.6531  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resultados_training   = []\n",
    "resultados_validation = []\n",
    "\n",
    "########################################################\n",
    "\n",
    "np.random.seed(SEED)\n",
    "for criterio in [\"gini\", \"entropy\"]:\n",
    "     for altura in [3, 5, None]:\n",
    "        \n",
    "        arbol = DecisionTreeClassifier(max_depth=altura, criterion=criterio)\n",
    "        arbol.fit(X_dev_np, y_dev_np)\n",
    "        \n",
    "        #Entrenamiento\n",
    "        y_pred = arbol.predict(X_dev_np) \n",
    "        resultados_training.append( get_accuracy(y_pred, y_dev_np) )\n",
    "        \n",
    "        #Validacion\n",
    "        y_pred = arbol.predict(X_eval_np)\n",
    "        resultados_validation.append( get_accuracy(y_pred, y_eval_np) )\n",
    "\n",
    "#########################################################\n",
    "\n",
    "df = pd.DataFrame(index=range(0,6))\n",
    "\n",
    "df[\"Altura máxima\"] = [3, 5, \"Inifinito\"] * 2\n",
    "df[\"Criterio de evaluación de corte\"] = [\"Gini\"] * 3 + [\"Ganancia de Información\"] * 3\n",
    "df[\"AUC ROC promedio (training)\"]   = resultados_training# reemplazar por resultados_training\n",
    "df[\"AUC ROC promedio (validación)\"] = resultados_validation # reemplazar por resultados_validation\n",
    "\n",
    "   \n",
    "display(HTML(\"<h3> TABLA 2 </h3>\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio Extra\n",
    "Para esto tomamos como base el arbol del notebook 4 y lo importamos a un archivo .py para usarlo. \n",
    "\n",
    "**Para probarlo, simplemente descomentar la linea del principio de este ejercicio donde se crea el arbol de decision**.\n",
    "\n",
    "Cambios:\n",
    "    - En las preguntas comparar por >= para tomar espacios continuos.\n",
    "    - Agregamos la entropia como calculo de ganancia\n",
    "    - Agregamos los parametros de profundidad maxima y seleccion de criterio para el arbol. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Comparación de algoritmos\n",
    "\n",
    "\n",
    "Se pide explorar distintas combinaciones de algoritmos de aprendizaje e hiperparámetros, de manera de buscar una performance óptima. Para este ejercicio es necesario que evalúen posibilidades utilizando la técnica de Grid Search. Como métrica de performance, usar siempre el área bajo la curva (AUC ROC) resultante de 5-fold cross-validation. \n",
    "\n",
    "Algoritmos a probar: KNN, árboles de decisión, LDA, Naive Bayes y SVM. Hiperparámetros: Revisar la documentación de cada uno para la búsqueda de combinaciones prometedoras.  \n",
    "\n",
    "Se pide generar un reporte que contenga: \n",
    "\n",
    "1. Una descripción de las distintas combinaciones consideradas y su performance asociada (las que consideren relevantes, con al menos la mejor combinación para cada algoritmo). \n",
    "\n",
    "1. Una breve explicación de los factores que creen que produjeron dicho resultado. \n",
    "\n",
    "En este punto evaluaremos tanto los hiperparámetros elegidos como las conclusiones relacionadas a por qué piensan que ciertos algoritmos funcionan mejor que otros para estos datos. \n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "**EJERCICIO EXTRA**: Utilizar RandomizedSearchCV con rangos de parámetros que contengan a los utilizados en el GridSearch. Analizar si se encontraron mejores combinaciones de parámetros que no hayan sido tenidas en cuenta con el GridSearch y cuál fue la diferencia de tiempo de ejecución. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "##############################################\n",
    "################# Auxiliares #################\n",
    "##############################################\n",
    "\n",
    "def top_resultados(grid, top=5):\n",
    "    ## Si quieren, pueden utilizar esta función para imprimir las mejores combinaciones de su grid\n",
    "    print(\"Top {} combinaciones\".format(top))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=False).head(top))\n",
    "\n",
    "def bot_resultados(grid, bot=5):\n",
    "    print(\"Bot {} combinaciones\".format(bot))\n",
    "    df = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    df[\"mean_score_validation\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    df[\"mean_score_training\"] = grid.cv_results_[\"mean_train_score\"]\n",
    "    display(df.sort_values(by=\"mean_score_validation\", ascending=True).head(bot))\n",
    "    \n",
    "def correr_y_mostrar(estimator, parameters, folds, top):\n",
    "    grid = GridSearchCV(estimator, parameters, cv=folds, scoring='roc_auc')\n",
    "    time_before = time.time()\n",
    "    grid.fit(X_dev_np, y_dev_np)\n",
    "    time_after = time.time()\n",
    "    top_resultados(grid, top)\n",
    "    bot_resultados(grid, top)\n",
    "    runtime = (time_after - time_before) * 1000.0 \n",
    "    return (runtime, grid)\n",
    "\n",
    "# Para usar en caso de tener probabilidades a priori\n",
    "priors = [(0.1,0.9),(0.2,0.8),(0.3,0.7),(0.4,0.6),(0.5,0.5),(0.6,0.4),(0.7,0.3),(0.8,0.2),(0.9,0.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este algoritmo decidimos usar solo los atributos criterio y max_depth, ya que son los mas simples a la hora de explicar como se comportan y como afectas a los datos de entrenamiento.\n",
    "\n",
    "Sin embargo, al hacer algunas pruebas nos encontramos con otro parametro que nos parecio interesante, a continuacion hacemos los analisis en los dos casos (solo con criterio y max_depth | agregando el nuevo parametro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>0.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>0.7062</td>\n",
       "      <td>0.8783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.7931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6854</td>\n",
       "      <td>0.9268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "51      gini          2                 0.7085               0.8030\n",
       "52      gini          3                 0.7062               0.8783\n",
       "1    entropy          2                 0.6979               0.7931\n",
       "2    entropy          3                 0.6855               0.8660\n",
       "3    entropy          4                 0.6854               0.9268"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot 5 combinaciones\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>mean_score_validation</th>\n",
       "      <th>mean_score_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>gini</td>\n",
       "      <td>44</td>\n",
       "      <td>0.5934</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>gini</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5979</td>\n",
       "      <td>0.9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>gini</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  mean_score_validation  mean_score_training\n",
       "93      gini         44                 0.5934               1.0000\n",
       "99      gini         50                 0.5971               1.0000\n",
       "57      gini          8                 0.5979               0.9988\n",
       "59      gini         10                 0.5994               0.9997\n",
       "58      gini          9                 0.6011               0.9997"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parametersDecisionTree = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':range(1,51)\n",
    "}\n",
    "\n",
    "(tiempoDecisionTree, grid_decision_tree) = correr_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree,\n",
    "    5,\n",
    "    5\n",
    ")\n",
    "\n",
    "parametersDecisionTree2 = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':range(1,51),\n",
    "    'min_samples_split':range(2, 30)\n",
    "}\n",
    "\n",
    "(tiempoDecisionTree2, grid_decision_tree_2) = correr_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree2,\n",
    "    5,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo con dos parametros\n",
    "\n",
    "A priori se puede ver que los mejores vs peores resultados tienen profundidades maximas bastante distintas(A excepcion del peor elemento con altura 6, suponemos que fue una muy mala muestra que justo dio ese resultado). Entre los mejores arboles en promedio no superan los 5 niveles, mientras que en los peores suele estar alrededor del 14/15.\n",
    "\n",
    "Una cosa importante a remarcar es que en los peores arboles, el score del set de entrenamiento es bastante alto (y 1 en varios casos), mientras que en los mejores este baja un poco. Esto se da por la tendencia a overfittear  data rapidamente de estos arboles a medida que aparecen mas niveles (Las hipotesis que toma se vuelven casos mas particulares).\n",
    "\n",
    "Por como se dan los resultados pareciera que la entropia funciona un poco mejor que gini como criterio, pero suponemos que esto no necesariamente es asi en el caso general. \n",
    "\n",
    "### Agregando min_samples_split\n",
    "\n",
    "Podemos ver que con min_samples_split el arbol se limita a cortar un nodo si hay al menos esa cantidad de samples que caen en el. \n",
    "\n",
    "Teniendo lo anterior en cuenta podemos observar que los arboles que dieron los mejores resultados fueron los que tuvieron mayor profundidad y mayor cantidad de samples como minimo para separar un nodo. Nuestra suposicion es que al ser relativamente alta la cantidad minima de splitteo, esto evita overfittear sobre casos no muy normales en los datos y obtener profundidad sobre informacion que es relevante. Pero manteniendo un limite a la hora de crear hipotesis demasiado particulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este estimador solo tomamos las probabilidades a priori de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersNaiveBayes = {\n",
    "    'priors':priors\n",
    "}\n",
    "\n",
    "(tiempoBayes, grid_bayes) = correr_y_mostrar(\n",
    "    GaussianNB(), \n",
    "    parametersNaiveBayes, \n",
    "    5, \n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista se puede observar que no hay mucha diferencia en los scores tanto de validacion como train y tambien entre los mejores y peores. Esto llama la atencion ya que la intuicion diria que la probabilidad a priori de las clases deberia influir en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersKNN = {\n",
    "    'n_neighbors' : list(range(1, 32)),\n",
    "    'weights'     : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "(tiempoKNN, grid_knn) = correr_y_mostrar(\n",
    "    KNeighborsClassifier(), \n",
    "    parametersKNN, \n",
    "    5, \n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parametersSVM = {\n",
    "    'C':[1e-15, 1e-5, 1e-2, 1.0, 200.0, 500.0, 100000.0],\n",
    "}\n",
    "\n",
    "(timepoSVM, grid_svm) = correr_y_mostrar(\n",
    "    LinearSVC(), \n",
    "    parametersSVM, \n",
    "    5,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este algoritmo decidimos usar el parametro C. Este controla el nivel de tolerancia al clasificar erroneamente las muestras, con lo que un C chico generaria un hiperplano con margen mas grande, permitiendo asi una hipotesis mas simple. Por otro lado tomando un C grande, se achica el margen del hiperplano y forzando a clasificar mejor los datos de entrenamiento.\n",
    "\n",
    "En los resultados se puede ver que con valores grandes de C la muestra tiende a \"overfittearse\", mientras que con valores mas chicos el score de validacion es mas alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1\n",
    "\n",
    "Para el primero probamos usar los parametros **svd**, **n_components** y **priori**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersLDA_svd = {\n",
    "    'solver'            :['svd'],\n",
    "    'priors'            :priors,\n",
    "    'n_components'      :[0, 1, 2, 3, 4, 5, 6],\n",
    "}\n",
    "\n",
    "(tiempoLDA_svd, grid_lda_svd) = correr_y_mostrar(\n",
    "    LDA(),\n",
    "    parametersLDA_svd,\n",
    "    5,\n",
    "    5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos llama la atencion que todos los scores den iguales variando los parametros(Algo parecido a lo que nos paso en **Naive Bayes**), lo que nos da dos suposiciones: \n",
    "- Por como funcione svd, el data set se comporta siempre igual\n",
    "- Hay algun tema con la tecnica que hace que de siempre lo mismo.\n",
    "\n",
    "Fuera de esto, podemos ver que el score de training y validacion difieren bastante. A continuacion, vamos a probar con otros solvers para comparar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2\n",
    "\n",
    "En este experimento vamos a usar los solvers **lsqr**(cuadrados minimos) y **eigen**, junto con **priors** y **shrinkage** para "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probamos con n_components para reduccion pero no afecto\n",
    "shrinkage = np.linspace(0.1,1.0).tolist()\n",
    "shrinkage.append('auto')\n",
    "\n",
    "parametersLDA = {\n",
    "    \"solver\": [\"lsqr\", \"eigen\"],\n",
    "    \"priors\": priors,\n",
    "    \"shrinkage\": shrinkage\n",
    "}\n",
    "\n",
    "(tiempoLDA, grid_lda) = correr_y_mostrar(\n",
    "    LDA(),\n",
    "    parametersLDA,\n",
    "    5,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple vista se puede notar la diferencia con **svd**, el peor score aqui es mejor que el mejor de **svd**. \n",
    "\n",
    "Por otro lado no parece influir mucho la tecnica que se use, ambos solvers parecen dar buenos resultados mientras que probabilidades a priori mas cercanas al **(0.5, 0.5)** quedan como mejor rankeadas.\n",
    "\n",
    "Algo importante a resaltar es **shrinkage**, valores mas cercanos al 1 dan muy buenos resultados. Reducen un poco el score en el set de entrenamiento pero el de validacion aumenta casi en un 0.1 comparado con los peores casos. Esto sugiere que el valor optimo esta aproximadamente en 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs:** \n",
    "- RandomizeSearchCV cuenta con el parametro **n_iter** para regular la cantidad de parametros que busca, esto lo vamos a usar a lo largo de los experimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliares para correr randomized search\n",
    "def correr_randomized_y_mostrar(estimator, parameters, folds, top,  iteraciones=None):\n",
    "    if(iteraciones is None):\n",
    "        grid = RandomizedSearchCV(estimator, parameters, cv=folds, scoring='roc_auc')\n",
    "    else:\n",
    "        grid = RandomizedSearchCV(estimator, parameters, cv=folds, scoring='roc_auc', n_iter=iteraciones)\n",
    "        \n",
    "    time_before = time.time()\n",
    "    grid.fit(X_dev_np, y_dev_np)\n",
    "    time_after = time.time()\n",
    "    top_resultados(grid, top)\n",
    "    bot_resultados(grid, top)\n",
    "    return (time_after - time_before) * 1000.0\n",
    "\n",
    "def verTiempo(original, random):\n",
    "    display(\"original: {:f}\".format(original))\n",
    "    display(\"random: {:f}\".format(random))\n",
    "    display(\"diferencia: {:f}\".format( np.absolute(original-random) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este experimento tomamos el arbol de decision con solo 2 parametros que discutimos en la primera parte del ejercicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersDecisionTree = {\n",
    "    'criterion':['entropy','gini'],\n",
    "    'max_depth':range(1,51)\n",
    "}\n",
    "\n",
    "tiempoRandomDecisionTree = correr_randomized_y_mostrar(\n",
    "    DecisionTreeClassifier(),\n",
    "    parametersDecisionTree,\n",
    "    5,\n",
    "    5,\n",
    "    100\n",
    ")\n",
    "\n",
    "verTiempo(tiempoDecisionTree, tiempoRandomDecisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser un espacio de busqueda discreto, grid y random search ven los mismos  elementos, dando asi los mismos resultados. Podemos ver que randomSearch tarda un poco menos en correr, pero no es significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersNaiveBayes = {\n",
    "    'priors':priors\n",
    "}\n",
    "\n",
    "#tiempoRandomBayes = correr_randomized_y_mostrar(\n",
    "#    GaussianNB(), \n",
    "#    parametersNaiveBayes, \n",
    "#    5, \n",
    "#    5\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "######################### Comparacion de Tiempos ####################\n",
    "#####################################################################\n",
    "#tiempoDecisionTree\n",
    "#tiempoBayes\n",
    "#tiempoKNN\n",
    "#tiempoLDA\n",
    "#timepoSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: \n",
    "### Diagnóstico Sesgo-Varianza. \n",
    "\n",
    "En este punto, se pide inspeccionar dos de sus mejores modelos encontrados hasta ahora: el mejor modelo de tipo árbol de decisión y el mejor de tipo SVM. Para ello:\n",
    "\n",
    "1. Graficar curvas de complejidad para cada modelo, variando la profundidad en el caso de árboles, y el hiperparámetro C en el caso de SVM. Diagnosticar cómo afectan al sesgo y a la varianza esos dos hiperparámetros.\n",
    "2. Graficar curvas de aprendizaje para cada modelo. En base a estas curvas, sacar conclusiones sobre si los algoritmos parecen haber alcanzado su límite, o bien si aumentar la cantidad de datos debería ayudar.\n",
    "3. Construir un modelo RandomForest con 200 árboles. Explorar para qué sirve el hiperparámetro max_features y cómo afecta a la performance del algoritmo mediante una curva de complejidad. Explicar por qué creen que se dieron los resultados obtenidos. Por último, graficar una curva de aprendizaje sobre los parámetros elegidos para determinar si sería útil o no conseguir más datos (usar  grid search para encontrar una buena combinación de parámetros).  \n",
    "\n",
    "\n",
    "**Atención**: Tener en cuenta que debemos seguir utilizando ROC AUC como métrica para estas curvas.\n",
    "\n",
    "**ver**: http://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "----\n",
    "**EJERCICIO EXTRA:** Utilizar RandomizedSearchCV para explorar la performance del algoritmo de Gradient Boosting y comparar con los resultados obtenidos en el punto (c).\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, cv=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Roc Auc Score\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=np.linspace(.1, 1.0, 5))\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std  = np.std(train_scores, axis=1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis=1)\n",
    "    test_scores_std   = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator, X, y, param, paramRange, plotTitle, parametroName):\n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=param, param_range=paramRange,\n",
    "        cv=5, scoring=\"roc_auc\")\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std  = np.std(train_scores, axis=1)\n",
    "    test_scores_mean  = np.mean(test_scores, axis=1)\n",
    "    test_scores_std   = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(plotTitle)\n",
    "    plt.xlabel(parametroName)\n",
    "    plt.ylabel(\"Roc Auc Score\")\n",
    "    lw = 2\n",
    "    \n",
    "    plt.semilogx(paramRange, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"red\", lw=lw)\n",
    "    plt.fill_between(paramRange, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"red\", lw=lw)\n",
    "    plt.semilogx(paramRange, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"blue\", lw=lw)\n",
    "    plt.fill_between(paramRange, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"blue\", lw=lw)\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeras curvas de complejidad\n",
    "\n",
    "Veamos como se comportan las curvas para los parametros de ambos estimadores.\n",
    "\n",
    "**Nota:** Para el arbol de decision usamos el primero que habiamos probado ya que tiene mejor score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-af96c8892fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m plot_validation_curve(svm,X_dev_np, y_dev_np, \"C\", [pow(10,x) for x in range(-10,2)],\n\u001b[1;32m      3\u001b[0m                       \"Curvas para SVM\", \"C\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_svm' is not defined"
     ]
    }
   ],
   "source": [
    "svm = grid_svm.best_estimator_\n",
    "plot_validation_curve(svm,X_dev_np, y_dev_np, \"C\", [pow(10,x) for x in range(-10,2)],\n",
    "                      \"Curvas para SVM\", \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que al crecer empieza a permitir menos clasificaciones erroneas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionTree = grid_decision_tree.best_estimator_\n",
    "plot_validation_curve(decisionTree,X_dev_np, y_dev_np, \"max_depth\", range(1,60),\n",
    "                      \"Curvas para Decision Tree\", \"Profundidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_validation_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4bd0b49fb482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m plot_validation_curve(RandomForestClassifier(),X_dev_np, y_dev_np,\n\u001b[0m\u001b[1;32m      3\u001b[0m                       \u001b[0;34m\"max_features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \"Curvas de Complejidad para Random Forest\", \"max_features\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_validation_curve' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "plot_validation_curve(RandomForestClassifier(),X_dev_np, y_dev_np,\n",
    "                      \"max_features\", range(1,201,10),\n",
    "                      \"Curvas de Complejidad para Random Forest\", \"max_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competencias\n",
    "\n",
    "La entrega del trabajo estará acompañada de una competencia en la cual deberán poner a prueba su mejor modelo y sobre todo, su capacidad para estimar sus resultados. \n",
    "\n",
    "Su tarea será estimar la performance (AUC ROC) que tendrá su mejor modelo en datos de evaluación (X_competencia). \n",
    "\n",
    "Para ello, deberán predecir las probabilidades de las distintas instancias con su modelo, enviarnos dichas probabilidades junto a una estimación con 4 decimales de cuál será el AUC ROC resultante y calcularemos el resultado real. El grupo que consiga acercarse más al valor real, será el grupo ganador.  \n",
    "\n",
    "Recomendamos no perder de vista esta competencia en el momento de separar los datos en los primeros puntos. \n",
    "\n",
    "Para esto, junto con la entrega del informe, deberán enviar un archivo en formato csv con las columnas “index” y “output” (ver ejemplo de archivo en: [y_competencia_ejemplo.csv](https://github.com/pbrusco/aa-notebooks/blob/master/TP1/y_competencia_ejemplo.csv)) y un valor esperado de AUC ROC. \n",
    "\n",
    "\n",
    "## Entrega\n",
    "- Contarán con un esqueleto en formato Jupyter Notebook en donde tendrán que completar las celdas faltantes (ya sea con explicaciones y gráficos o código). \n",
    "- El notebook final deberá ser entregado en formatos .html e .ipynb. Es necesario que los resultados puedan reproducirse al ejecutar todas las celdas en orden (Kernel - Restart and Run All) utilizando las bibliotecas requeridas en el archivo: requirements.txt del repositorio. \n",
    "- Tienen tiempo hasta las 23:59hs del día miércoles 17/10/2018. La entrega se debe realizar a través del campus virtual y debe contener el informe.\n",
    "- El trabajo deberá elaborarse en grupos de 3 personas.\n",
    "- Se podrán pedir pruebas de integridad y autoría; es decir, verificar que la salida solicitada es fruto del modelo presentado y que el modelo fue construido según lo requerido en este enunciado.\n",
    "- La evaluación será grupal y se basará en la calidad del informe (presentación, claridad, prolijidad); la originalidad, practicidad y coherencia técnica de la solución; la corrección y solidez de las pruebas realizadas.\n",
    "- En el primer parcial se incluirá una pregunta sobre la solución entregada. Esa pregunta no influirá en la nota del parcial, pero sí en la nota individual del TP1.\n",
    "- La participación en la competencia es obligatoria. De todas maneras, el resultado no incidirán en la nota de la materia.\n",
    "- Los ejercicios extra son opcionales para aprobar el TP, pero son obligatorios para promocionar la materia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
